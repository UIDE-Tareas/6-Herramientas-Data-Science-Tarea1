{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e47d53a",
   "metadata": {},
   "source": [
    "<div style=\"display: table; width: 100%;\">\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 70%;\">\n",
    "    <h1>Herramientas para Data Science</h1>\n",
    "  </div>\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 30%;\">\n",
    "    <img src=\"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/blob/main/Assets/UideLogo.png?raw=true\" alt=\"logo UIDE\" style=\"width:50%;\">\n",
    "  </div>\n",
    "</div>\n",
    "<hr />\n",
    "\n",
    "### üü¶ Componente Pr√°ctico 1  \n",
    "üü° Grupo: 3      \n",
    "üü° Semana: 1      \n",
    "üü° Docente:  Ing. Iv√°n Garc√≠a S., PhD. (idgs78@hotmail.com)     \n",
    "\n",
    "### üü¶ Realizado por:   \n",
    "Estudiantes\n",
    "\n",
    "üíª Evelin Rosero Ordo√±ez   \n",
    "\n",
    "üíª Marjorie Muso Tandalla\n",
    "\n",
    "üíª Jos√© Espinoza Bone\n",
    "\n",
    "### üü¶ Objetivo y alcance del trabajo \n",
    "- Esta pr√°ctica tiene el objetivo de realizar un preprocesamiento de datos y un An√°lisis \n",
    "exploratorio de datos (estad√≠sticas y visualizaci√≥n) de las variables m√°s relevantes \n",
    "que considere para el prop√≥sito de predicci√≥n de c√°ncer de mama. Al finalizar la \n",
    "pr√°ctica, los maestrantes podr√°n manipular adecuadamente un dataset de datos \n",
    "estructurados (alfanum√©ricos). [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "\n",
    "\n",
    "\n",
    "- Esta pr√°ctica tiene el objetivo de realizar un preprocesamiento de datos y un An√°lisis \n",
    "exploratorio de datos (estad√≠sticas y visualizaci√≥n) de las variables m√°s relevantes \n",
    "que considere para el prop√≥sito de predicci√≥n de supervivencia en el desastre del Titanic. Al finalizar la \n",
    "pr√°ctica, los maestrantes podr√°n manipular adecuadamente un dataset de datos \n",
    "estructurados (alfanum√©ricos). [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\n",
    "\n",
    "\n",
    "\n",
    "### üü¶ C√≥digo fuente original\n",
    "Con [git](https://git-scm.com/) instalado. En Windows, Linux o MacOS ejecutar el comando.\n",
    "\n",
    "```\n",
    "git clone \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1.git\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bb6d5",
   "metadata": {},
   "source": [
    "# 0Ô∏è‚É£ Preparar entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d374159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Installing deps.\n",
      "‚è≥ c:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install --upgrade pip\n",
      "‚è≥ c:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\python.exe -m pip install numpy pandas matplotlib seaborn scikit-learn requests wcwidth\n",
      "Deps installed.\n",
      "\n",
      "‚ÑπÔ∏è  Environment Info:\n",
      "Python Version: 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "Platform: win32\n",
      "Executable Path: c:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n",
      "Current Working Directory: c:\\Users\\Megam\\OneDrive\\Escritorio\\6-Herramientas-Data-Science-Tarea1\n",
      "VIRTUAL_ENV: None\n",
      "sys.prefix: c:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\n",
      "sys.base_prefix: c:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import zipfile\n",
    "from typing import Optional, Iterable\n",
    "from dataclasses import dataclass\n",
    "from typing import cast\n",
    "from typing import Tuple\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Libs a instalar\n",
    "LIBS = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"requests\",\n",
    "    \"wcwidth\",\n",
    "]\n",
    "\n",
    "class ConsoleColor(Enum):\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    BLUE = \"\\033[94m\"\n",
    "    MAGENTA = \"\\033[95m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    WHITE = \"\\033[97m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def PrintColor(message: str, color: ConsoleColor) -> str:\n",
    "    RESET = ConsoleColor.RESET.value\n",
    "    return f\"{color.value}{message}{RESET}\"\n",
    "\n",
    "\n",
    "def ShowMessage(\n",
    "    message: str, title: str, icon: str, color: ConsoleColor, end: str = \"\\n\"\n",
    "):\n",
    "    colored_title = PrintColor(icon + f\"  \" + title.upper() + \":\", color)\n",
    "    print(f\"{colored_title} {message}\", end=end)\n",
    "\n",
    "\n",
    "def ShowInfoMessage(\n",
    "    message: str, title: str = \"Info\", icon: str = \"‚ÑπÔ∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.CYAN, end)\n",
    "\n",
    "\n",
    "def ShowSuccessMessage(\n",
    "    message: str, title: str = \"Success\", icon: str = \"‚úÖ\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.GREEN, end)\n",
    "\n",
    "\n",
    "def ShowErrorMessage(\n",
    "    message: str, title: str = \"Error\", icon: str = \"‚ùå\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.RED, end)\n",
    "\n",
    "\n",
    "def ShowWarningMessage(\n",
    "    message: str, title: str = \"Warning\", icon: str = \"‚ö†Ô∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.YELLOW, end)\n",
    "\n",
    "\n",
    "# Funcion para ejecutar comandos\n",
    "def RunCommand(\n",
    "    commandList: list[str], printCommand: bool = True, printError: bool = True\n",
    ") -> subprocess.CompletedProcess[str]:\n",
    "    print(\"‚è≥\", \" \".join(commandList))\n",
    "\n",
    "    if printCommand:\n",
    "        proc = subprocess.Popen(\n",
    "            commandList,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True,\n",
    "        )\n",
    "\n",
    "        out_lines: list[str] = []\n",
    "        assert proc.stdout is not None\n",
    "        for line in proc.stdout:\n",
    "            print(line, end=\"\")\n",
    "            out_lines.append(line)\n",
    "\n",
    "        proc.wait()\n",
    "        err_text = \"\"\n",
    "        if proc.stderr is not None:\n",
    "            err_text = proc.stderr.read() or \"\"\n",
    "\n",
    "        if proc.returncode != 0 and printError and err_text:\n",
    "            ShowErrorMessage(err_text, \"\", end=\"\")\n",
    "            # print(err_text, end=\"\")\n",
    "\n",
    "        return subprocess.CompletedProcess(\n",
    "            args=commandList,\n",
    "            returncode=proc.returncode,\n",
    "            stdout=\"\".join(out_lines),\n",
    "            stderr=err_text,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        result = subprocess.run(\n",
    "            commandList, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "        if result.returncode != 0 and printError and result.stderr:\n",
    "            ShowErrorMessage(result.stderr, \"\", end=\"\")\n",
    "            # print(result.stderr, end=\"\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# Funci√≥n para instalar las dependencias\n",
    "def InstallDeps(libs: Optional[list[str]] = None):\n",
    "    print(\"‚ÑπÔ∏è Installing deps.\")\n",
    "    printCommand = False\n",
    "    printError = True\n",
    "    RunCommand(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"],\n",
    "        printCommand=printCommand,\n",
    "        printError=printError,\n",
    "    )\n",
    "    if libs is None or libs.count == 0:\n",
    "        print(\"No hay elementos a instalar.\")\n",
    "    else:\n",
    "        RunCommand(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", *libs],\n",
    "            printCommand=printCommand,\n",
    "            printError=printError,\n",
    "        )\n",
    "        print(\"Deps installed.\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar info el ambiente de ejecuci√≥n\n",
    "def ShowEnvironmentInfo():\n",
    "    print(\"‚ÑπÔ∏è  Environment Info:\")\n",
    "    print(\"Python Version:\", sys.version)\n",
    "    print(\"Platform:\", sys.platform)\n",
    "    print(\"Executable Path:\", sys.executable)\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "    print(\"VIRTUAL_ENV:\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "    print(\"sys.prefix:\", sys.prefix)\n",
    "    print(\"sys.base_prefix:\", sys.base_prefix)\n",
    "    print()\n",
    "\n",
    "\n",
    "InstallDeps(LIBS)\n",
    "ShowEnvironmentInfo()\n",
    "import requests\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BoxStyle:\n",
    "    TL: str\n",
    "    TR: str\n",
    "    BL: str\n",
    "    BR: str\n",
    "    H: str\n",
    "    V: str\n",
    "\n",
    "class TitleBoxLineStyle(Enum):\n",
    "    SIMPLE = BoxStyle(\"‚îå\", \"‚îê\", \"‚îî\", \"‚îò\", \"‚îÄ\", \"‚îÇ\")\n",
    "    DOUBLE = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ïê\", \"‚ïë\")\n",
    "    ROUNDED = BoxStyle(\"‚ï≠\", \"‚ïÆ\", \"‚ï∞\", \"‚ïØ\", \"‚îÄ\", \"‚îÇ\")\n",
    "    HEAVY = BoxStyle(\"‚îè\", \"‚îì\", \"‚îó\", \"‚îõ\", \"‚îÅ\", \"‚îÉ\")\n",
    "    ASCII = BoxStyle(\"+\", \"+\", \"+\", \"+\", \"-\", \"|\")\n",
    "    DOUBLE_BOLD = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ï¨\", \"‚ïë\")\n",
    "    BLOCK = BoxStyle(\"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\")\n",
    "    HEAVY_CROSS = BoxStyle(\"‚ïí\", \"‚ïï\", \"‚ïò\", \"‚ïõ\", \"‚ï™\", \"‚îÉ\")\n",
    "    METAL = BoxStyle(\"‚ïû\", \"‚ï°\", \"‚ïò\", \"‚ïõ\", \"‚ïê\", \"‚ïë\")\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar un t√≠tulo con recuadro\n",
    "def ShowTitleBox(\n",
    "    text: str,\n",
    "    max_len: int = 100,\n",
    "    boxLineStyle: TitleBoxLineStyle = TitleBoxLineStyle.SIMPLE,\n",
    "    color: ConsoleColor = ConsoleColor.CYAN,\n",
    "):\n",
    "    try:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            from wcwidth import wcswidth as _w\n",
    "\n",
    "            n = _w(s)\n",
    "            return n if n >= 0 else len(s)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            return len(s)\n",
    "\n",
    "    pad = 1\n",
    "    tlen = vislen(text)\n",
    "    inner = max(max_len, tlen)\n",
    "    left = (inner - tlen) // 2\n",
    "    right = inner - tlen - left\n",
    "\n",
    "    top = f\"{boxLineStyle.value.TL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.TR}\"\n",
    "    mid = f\"{boxLineStyle.value.V}{' ' * pad}{' ' * left}{text}{' ' * right}{' ' * pad}{boxLineStyle.value.V}\"\n",
    "    bot = f\"{boxLineStyle.value.BL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.BR}\"\n",
    "    print(PrintColor(\"\\n\".join([top, mid, bot]), color))\n",
    "\n",
    "\n",
    "# Funci√≥n para descargar un archivo\n",
    "def DownloadFile(uri: str, filename: str, overwrite: bool = False, timeout: int = 20):\n",
    "    dest = Path(filename).resolve()\n",
    "    if dest.exists() and dest.is_file() and dest.stat().st_size > 0 and not overwrite:\n",
    "        print(\n",
    "            f'‚úÖ Ya existe: \"{dest}\". No se descarga (use overwrite=True para forzar).'\n",
    "        )\n",
    "        return\n",
    "    if dest.parent and not dest.parent.exists():\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f'‚ÑπÔ∏è Descargando \"{uri}\" ‚Üí \"{dest}\"')\n",
    "    try:\n",
    "        with requests.get(uri, stream=True, timeout=timeout) as resp:\n",
    "            resp.raise_for_status()\n",
    "            tmp = dest.with_suffix(dest.suffix + \".part\")\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(chunk_size=1024 * 64):\n",
    "                    if chunk:  # filtra keep-alive chunks\n",
    "                        f.write(chunk)\n",
    "            tmp.replace(dest)\n",
    "        print(f'‚úÖ Archivo \"{dest}\" descargado exitosamente.')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error al descargar: {e}\")\n",
    "\n",
    "\n",
    "# Funci√≥n para descomprimir un archivo zip\n",
    "def UnzipFile(filename: str, outputDir: str):\n",
    "    print(f'‚ÑπÔ∏è Descomprimiendo \"{filename}\" en \"{outputDir}\"')\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(outputDir)\n",
    "        print(f\"Descomprimido en: {os.path.abspath(outputDir)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413cec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar libraries\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import cast\n",
    "from typing import Tuple\n",
    "from enum import Enum\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurar opciones de Pandas\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pandas.set_option(\"display.max_rows\", None)\n",
    "pandas.set_option(\"display.max_columns\", None) \n",
    "\n",
    "# Funci√≥n para mostrar la informaci√≥n del DataFrame.\n",
    "def ShowDfInfo(df: pandas.DataFrame, title):\n",
    "    display(f\"‚ÑπÔ∏è INFO {title} ‚ÑπÔ∏è\")\n",
    "    df.info()\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n primeras filas del DataFrame.\n",
    "def ShowDfHead(df: pandas.DataFrame, title: str, headQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: Primeros {headQty} elementos.\")\n",
    "    display(df.head(headQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n √∫ltimas filas del DataFrame.\n",
    "def ShowDfTail(df: pandas.DataFrame, title: str, tailQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: √öltimos {tailQty} elementos.\")\n",
    "    display(df.tail(tailQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Mostrar el tama√±o del DataFrame\n",
    "def ShowDfShape(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è {title} - Tama√±o de los datos\")\n",
    "    display(f\"{df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la estad√≠stica descriptiva de todas las columnas del DataFrame, por tipo de dato.\n",
    "def ShowDfStats(df: pandas.DataFrame, title: str = \"\"):\n",
    "    display(f\"‚ÑπÔ∏è Estad√≠stica descriptiva - {title}\")\n",
    "    numeric_cols = df.select_dtypes(include=\"number\")\n",
    "    if not numeric_cols.empty:\n",
    "        display(\"    üî¢ Columnas num√©ricas\".upper())\n",
    "        numeric_desc = (\n",
    "            numeric_cols.describe().round(2).T\n",
    "        )  # Transpuesta para a√±adir columna\n",
    "        numeric_desc[\"var\"] = numeric_cols.var(numeric_only=True).round(2)\n",
    "        display(numeric_desc.T)\n",
    "    non_numeric_cols = df.select_dtypes(\n",
    "        include=[\"boolean\", \"string\", \"category\", \"object\"]\n",
    "    )\n",
    "    if not non_numeric_cols.empty:\n",
    "        display(\"    üî° Columnas no num√©ricas\".upper())\n",
    "        non_numeric_desc = non_numeric_cols.describe()\n",
    "        display(non_numeric_desc)\n",
    "    datetime_cols = df.select_dtypes(include=[\"datetime\", \"datetimetz\"])\n",
    "    if not datetime_cols.empty:\n",
    "        display(\"    üìÖ Columnas fechas\".upper())\n",
    "        datetime_desc = datetime_cols.describe()\n",
    "        display(datetime_desc)\n",
    "\n",
    "# Funci√≥n para mostrar una visi√≥n general completa del DataFrame\n",
    "def ShowFullDfOverview(df, title, headQty=5, tailQty=5):\n",
    "    ShowDfInfo(df, title)\n",
    "    ShowDfStats(df, title)\n",
    "    ShowDfShape(df, title)\n",
    "    ShowDfHead(df, title, headQty=headQty)\n",
    "    ShowDfTail(df, title, tailQty=tailQty)\n",
    "\n",
    "# Funci√≥n para mostrar los valores nulos o NaN de cada columna en un DataFrame\n",
    "def ShowDfNanValues(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è Contador de valores Nulos - {title}\")\n",
    "    nulls_count = df.isnull().sum()\n",
    "    nulls_df = nulls_count.reset_index()\n",
    "    nulls_df.columns = [\"Columna\", \"Cantidad_Nulos\"]\n",
    "    display(nulls_df)\n",
    "    display()\n",
    "\n",
    "\n",
    "# Tipos de correlaci√≥n\n",
    "class CorrelationType(Enum):\n",
    "    ALL = \"all\"\n",
    "    STRONG = \"strong\"\n",
    "    WEAK = \"weak\"\n",
    "\n",
    "# Muestra las correlaciones completas, d√©biles y fuertes.\n",
    "def ShowDfCorrelation(\n",
    "    df: pandas.DataFrame,\n",
    "    title: str,\n",
    "    fig: Optional[Figure] = None,\n",
    "    ax: Optional[Axes] = None,\n",
    "    level: CorrelationType = CorrelationType.ALL,\n",
    "    umbral: float = 0.6,\n",
    "    showTable: bool = False,\n",
    "    figsize: tuple = (8, 6),\n",
    "    annotate: bool = True,\n",
    "):\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    display(f\"‚ÑπÔ∏è {(title).upper()} - Matriz de Correlaci√≥n, Type: {level.name}\")\n",
    "\n",
    "    corr = df.select_dtypes(include=[\"number\"]).corr().copy()\n",
    "\n",
    "    if level == CorrelationType.STRONG:\n",
    "        corr = corr.where(np.abs(corr) >= umbral)\n",
    "    elif level == CorrelationType.WEAK:\n",
    "        corr = corr.where(np.abs(corr) < umbral)\n",
    "        np.fill_diagonal(corr.values, 1)\n",
    "    elif level != CorrelationType.ALL:\n",
    "        raise ValueError(f\"Invalid level: {level}\")\n",
    "\n",
    "    cax = ax.matshow(corr, vmin=-1, vmax=1)\n",
    "\n",
    "    cols = corr.columns\n",
    "    ax.set_xticks(range(len(cols)))\n",
    "    ax.set_yticks(range(len(cols)))\n",
    "    ax.set_xticklabels(cols, rotation=90, ha=\"left\")\n",
    "    ax.set_yticklabels(cols)\n",
    "\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    if annotate:\n",
    "        for (i, j), value in np.ndenumerate(corr.values):\n",
    "            if not np.isnan(value):\n",
    "                ax.text(j, i, f\"{value:+.2f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    if level == CorrelationType.ALL:\n",
    "        titulo = \"Matriz de correlaci√≥n completa\"\n",
    "    else:\n",
    "        titulo = f\"Matriz de correlaci√≥n ({level.name}, umbral={umbral})\"\n",
    "\n",
    "    total_elementos = corr.size\n",
    "    total_nodiagonal = corr.size - corr.shape[0]\n",
    "    total_nan = corr.isna().sum().sum()\n",
    "    total_validos = total_elementos - total_nan - corr.shape[0]\n",
    "\n",
    "    titulo = (\n",
    "        f\"{titulo}, Total Matriz: {total_nodiagonal}, \"\n",
    "        f\"Total v√°lidos: {total_validos} ({((total_validos * 100) / total_nodiagonal):.2f}%)\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(titulo, pad=20)\n",
    "    ax.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if showTable:\n",
    "        display(corr)\n",
    "\n",
    "    return fig, corr\n",
    "\n",
    "def NormalizeColumnNames(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    df.columns = [\n",
    "        col.strip().title().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "def DropColumns(df: pandas.DataFrame, toDrop: list[str]):\n",
    "    if not toDrop: \n",
    "        return df\n",
    "    return df.drop(columns=[c.strip().title().replace(\" \", \"\").replace(\"_\", \"\") for c in toDrop if c in df.columns])\n",
    "\n",
    "# Para almacenar los datos del dataset\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    X: pandas.DataFrame\n",
    "    y: pandas.DataFrame\n",
    "\n",
    "# Para almacenar los datos de split del dataset.\n",
    "@dataclass\n",
    "class DatasetSplit:\n",
    "    Train: Dataset\n",
    "    Test: Dataset\n",
    "\n",
    "# Muestra el head de cada componente del split.\n",
    "def ShowDatasetSplitHead(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    ShowDfHead(split.Train.X, f\"{title} - X Train\", headQty)\n",
    "    ShowDfHead(split.Train.y, f\"{title} - y Train\", headQty)\n",
    "    ShowDfHead(split.Test.X, f\"{title} - X Test\", headQty)\n",
    "    ShowDfHead(split.Test.y, f\"{title} - y Test\", headQty)\n",
    "\n",
    "# Muestra la informaci√≥n del Dataset\n",
    "def ShowDatasetInfo(data: Dataset, title):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - Caracteristicas - X\"\n",
    "    ShowDfInfo(data.X, title)\n",
    "    ShowDfShape(data.X, title)\n",
    "    ShowDfStats(data.X, title)\n",
    "    ShowDfNanValues(data.X, title)\n",
    "    ShowDfHead(data.X, title)\n",
    "    ShowDfTail(data.X, title)\n",
    "    title = f\"{tAux} - Caracter√≠sticas - y\"\n",
    "    ShowDfInfo(data.y, title)\n",
    "    ShowDfShape(data.y, title)\n",
    "    ShowDfStats(data.y, title)\n",
    "    ShowDfNanValues(data.y, title)\n",
    "    ShowDfHead(data.y, title)\n",
    "    ShowDfTail(data.y, title)\n",
    "    \n",
    "# Muestra la informaci√≥n del Dataset Split\n",
    "def ShowDatasetSplitInfo(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - TRAIN\"\n",
    "    ShowDatasetInfo(split.Train, title)\n",
    "    title = f\"{tAux} - TEST\"\n",
    "    ShowDatasetInfo(split.Test, title)\n",
    "\n",
    "# Realiza el split del Dataset, en Train y test utilizando el ratio.\n",
    "def SplitDataset(\n",
    "    data: Dataset, trainRatio: float = 0.8, randomState: int = 42\n",
    ") -> DatasetSplit:\n",
    "    y_strat = data.y.iloc[:, 0]\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(\n",
    "        data.X,\n",
    "        data.y,\n",
    "        train_size=trainRatio,\n",
    "        random_state=randomState,\n",
    "        stratify=y_strat,\n",
    "    )\n",
    "    return DatasetSplit(\n",
    "        Train=Dataset(X=XTrain.reset_index(drop=True), y=yTrain.reset_index(drop=True)),\n",
    "        Test=Dataset(X=XTest.reset_index(drop=True), y=yTest.reset_index(drop=True)),\n",
    "    )\n",
    "\n",
    "# Para almacenar los datos del dataset aplicado el escalador.\n",
    "@dataclass\n",
    "class ScaledDatasetSplit(DatasetSplit):\n",
    "    Scaler: StandardScaler\n",
    "\n",
    "# Escala el split usando StandardScaler y retorna el split escalado.\n",
    "def ScaleDatasetSplit(\n",
    "    split: DatasetSplit, withMean: bool = True, withStd: bool = True\n",
    ") -> ScaledDatasetSplit:\n",
    "    scaler = StandardScaler(with_mean=withMean, with_std=withStd)\n",
    "    XTrain = scaler.fit_transform(split.Train.X)\n",
    "    XTest = scaler.transform(split.Test.X)\n",
    "    XTrainScaled = split.Train.X.copy()\n",
    "    XTestScaled = split.Test.X.copy()\n",
    "    XTrainScaled.loc[:, :] = XTrain\n",
    "    XTestScaled.loc[:, :] = XTest\n",
    "    TrainScaled = Dataset(X=XTrainScaled, y=split.Train.y.copy())\n",
    "    TestScaled = Dataset(X=XTestScaled, y=split.Test.y.copy())\n",
    "    return ScaledDatasetSplit(Train=TrainScaled, Test=TestScaled, Scaler= scaler)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce2840",
   "metadata": {},
   "source": [
    "# TITANIC DATASET 1Ô∏è‚É£ Business Understanding - Entender el negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16432a0",
   "metadata": {},
   "source": [
    "| Columna         | Descripci√≥n                                                                                                                                                  |\n",
    "| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **PassengerId** | Identificador √∫nico asignado a cada pasajero en el dataset. No tiene significado real en el viaje, solo sirve como √≠ndice.                                   |\n",
    "| **Survived**    | Indica si el pasajero **sobrevivi√≥ (1)** o **muri√≥ (0)**. Es la variable objetivo en la mayor√≠a de proyectos de Machine Learning sobre este dataset.         |\n",
    "| **Pclass**      | Clase del boleto del pasajero: **1 = Primera clase**, **2 = Segunda clase**, **3 = Tercera clase**. Representa una medida indirecta de nivel socioecon√≥mico. |\n",
    "| **Name**        | Nombre completo del pasajero, generalmente incluye tratamiento o t√≠tulo social (Mr., Mrs., Miss, etc.).                                                      |\n",
    "| **Sex**         | Sexo del pasajero: **male** (hombre) o **female** (mujer).                                                                                                   |\n",
    "| **Age**         | Edad del pasajero en a√±os. Puede contener valores faltantes. Los ni√±os peque√±os pueden aparecer con valores decimales.                                       |\n",
    "| **SibSp**       | N√∫mero de **hermanos (siblings)** y **c√≥nyuges (spouses)** que viajaban con el pasajero en el Titanic.                                                       |\n",
    "| **Parch**       | N√∫mero de **padres (parents)** e **hijos (children)** que viajaban con el pasajero.                                                                          |\n",
    "| **Ticket**      | C√≥digo del boleto del pasajero. Puede incluir letras y n√∫meros; no cumple un formato est√°ndar.                                                               |\n",
    "| **Fare**        | Tarifa pagada por el pasajero por su boleto. El valor depende de la clase y otras condiciones del viaje.                                                     |\n",
    "| **Cabin**       | N√∫mero de cabina asignada. Muchos valores est√°n vac√≠os porque la mayor√≠a de pasajeros no ten√≠a cabina asignada (especialmente en 3ra clase).                 |\n",
    "| **Embarked**    | Puerto de embarque: **C = Cherbourg**, **Q = Queenstown**, **S = Southampton**.                                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7516605",
   "metadata": {},
   "source": [
    "# TITANIC DATASET 2Ô∏è‚É£ Data preparation - Preparaci√≥n de los datos\n",
    "- Se descargan los archivos CSV. \n",
    "- Se eliminan columnas innecesarias.\n",
    "- Se especifica bien los tipos de datos.\n",
    "- Se aplica one hot encoding si es necesario a columnas nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4b656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ñà                                 EXPLORACI√ìN INICIAL TITANIC DATASET                                  ‚ñà\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m\n",
      "\u001b[96m‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ                                         CARGANDO EL DATASET                                          ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\u001b[0m\n",
      "‚úÖ Ya existe: \"C:\\Users\\Megam\\OneDrive\\Escritorio\\6-Herramientas-Data-Science-Tarea1\\Temp\\TitanicTest.csv\". No se descarga (use overwrite=True para forzar).\n",
      "‚úÖ Ya existe: \"C:\\Users\\Megam\\OneDrive\\Escritorio\\6-Herramientas-Data-Science-Tarea1\\Temp\\TitanicTrain.csv\". No se descarga (use overwrite=True para forzar).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sibsp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>EmbarkedCherbourg</th>\n",
       "      <th>EmbarkedQueenstown</th>\n",
       "      <th>EmbarkedSouthampton</th>\n",
       "      <th>SexFemale</th>\n",
       "      <th>SexMale</th>\n",
       "      <th>Familysize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  Sibsp  Parch  Fare  EmbarkedCherbourg  \\\n",
       "0         0       3 22.00      1      0  7.25              False   \n",
       "1         1       1 38.00      1      0 71.28               True   \n",
       "2         1       3 26.00      0      0  7.92              False   \n",
       "3         1       1 35.00      1      0 53.10              False   \n",
       "4         0       3 35.00      0      0  8.05              False   \n",
       "\n",
       "   EmbarkedQueenstown  EmbarkedSouthampton  SexFemale  SexMale  Familysize  \n",
       "0               False                 True      False     True           2  \n",
       "1               False                False       True    False           2  \n",
       "2               False                 True       True    False           1  \n",
       "3               False                 True       True    False           2  \n",
       "4               False                 True      False     True           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Survived'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     74\u001b[39m ShowTitleBox(\u001b[33m\"\u001b[39m\u001b[33mCARGANDO EL DATASET\u001b[39m\u001b[33m\"\u001b[39m, color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n\u001b[32m     75\u001b[39m title = \u001b[33m\"\u001b[39m\u001b[33mData original\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m titanicDatasetSplit = \u001b[43mLoadTitanicDatasetSplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m ShowDatasetSplitInfo(titanicDatasetSplit, \u001b[33m\"\u001b[39m\u001b[33mTitanic Dataset Split\u001b[39m\u001b[33m\"\u001b[39m, headQty=\u001b[32m10\u001b[39m)\n\u001b[32m     80\u001b[39m CORR_UMBRAL = \u001b[32m0.3\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mLoadTitanicDatasetSplit\u001b[39m\u001b[34m(toDrop)\u001b[39m\n\u001b[32m     62\u001b[39m XTrain = dfTrain.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     63\u001b[39m yTrain = dfTrain[[\u001b[33m\"\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m XTest  = \u001b[43mdfTest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSurvived\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m yTest  = dfTest[[\u001b[33m\"\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetSplit(\n\u001b[32m     67\u001b[39m     Train=Dataset(X=XTrain, y=yTrain),\n\u001b[32m     68\u001b[39m     Test=Dataset(X=XTest, y=yTest)\n\u001b[32m     69\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Survived'] not found in axis\""
     ]
    }
   ],
   "source": [
    "DOWNLOADS_DIR = \"Temp\"\n",
    "TITANIC_TEST_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicTest.csv\"\n",
    "TITANIC_TEST_GENDER_SUB_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicGenderSub.csv\"\n",
    "TITANIC_TRAIN_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicTrain.csv\"\n",
    "TITANIC_TEST_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicTest.csv\")\n",
    "TITANIC_TRAIN_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicTrain.csv\")\n",
    "TITANIC_TEST_GENDER_SUB_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicGenderSub.csv\")\n",
    "\n",
    "\n",
    "    \n",
    "def LoadTitanicDatasetSplit(toDrop:list[str] = [])-> DatasetSplit:\n",
    "    toDrop = [x for x in toDrop if x != \"Survived\"]\n",
    "    DownloadFile(TITANIC_TEST_DATA_URL, TITANIC_TEST_FILENAME)\n",
    "    DownloadFile(TITANIC_TRAIN_DATA_URL, TITANIC_TRAIN_FILENAME)\n",
    "    DownloadFile(TITANIC_TEST_GENDER_SUB_DATA_URL, TITANIC_TEST_GENDER_SUB_FILENAME)\n",
    "    dfTrain = pd.read_csv(TITANIC_TRAIN_FILENAME)\n",
    "    dfTest = pd.read_csv(TITANIC_TEST_FILENAME)\n",
    "    dfTestGenderSub = pd.read_csv(TITANIC_TEST_FILENAME)\n",
    "\n",
    "    toDrop = [\"Cabin\", \"PassengerId\", \"Ticket\", \"Name\"]\n",
    "    dfTrain = dfTrain.drop(columns=toDrop)\n",
    "    dfTest  = dfTest.drop(columns=toDrop)\n",
    "\n",
    "    dtypeMap = {\n",
    "        \"Survived\": \"int64\",\n",
    "        \"Pclass\": \"int64\",\n",
    "        \"Sex\": \"string\",\n",
    "        \"Age\": \"float64\",\n",
    "        \"SibSp\": \"int64\",\n",
    "        \"Parch\": \"int64\",\n",
    "        \"Fare\": \"float64\",\n",
    "        \"Embarked\": \"string\"\n",
    "    }\n",
    "\n",
    "    dfTrain = dfTrain.astype(dtypeMap)\n",
    "    dfTest  = dfTest.astype({col: dtypeMap[col] for col in dfTest.columns})\n",
    "\n",
    "    mapEmbarked = {\n",
    "        \"S\": \"Southampton\",\n",
    "        \"C\": \"Cherbourg\",\n",
    "        \"Q\": \"Queenstown\"\n",
    "    }\n",
    "    dfTrain[\"Embarked\"] = dfTrain[\"Embarked\"].replace(mapEmbarked)\n",
    "    dfTest[\"Embarked\"]  = dfTest[\"Embarked\"].replace(mapEmbarked)\n",
    "\n",
    "    dfTrain = pd.get_dummies(dfTrain, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "    dfTest  = pd.get_dummies(dfTest, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "\n",
    "    dfTrain = pd.get_dummies(dfTrain, columns=[\"Sex\"], prefix=\"Sex\", drop_first=False)\n",
    "    dfTest  = pd.get_dummies(dfTest, columns=[\"Sex\"], prefix=\"Sex\", drop_first=False)\n",
    "\n",
    "    dfTrain[\"FamilySize\"] = dfTrain[\"SibSp\"] + dfTrain[\"Parch\"] + 1\n",
    "    dfTest[\"FamilySize\"] = dfTest[\"SibSp\"] + dfTest[\"Parch\"] + 1\n",
    "\n",
    "    meanAge = dfTrain[\"Age\"].mean()\n",
    "    dfTrain[\"Age\"] = dfTrain[\"Age\"].fillna(meanAge)\n",
    "    dfTest[\"Age\"]  = dfTest[\"Age\"].fillna(meanAge)\n",
    "\n",
    "    NormalizeColumnNames(dfTrain)\n",
    "    NormalizeColumnNames(dfTest)\n",
    "\n",
    "    dfTrain = DropColumns(dfTrain, toDrop)\n",
    "    dfTest  = DropColumns(dfTest, toDrop)\n",
    "\n",
    "    display(dfTrain.head(5))\n",
    "    display(dfTest.head(5))\n",
    "    print(\"-----------------------\")\n",
    "    XTrain = dfTrain.drop(columns=[\"Survived\"])\n",
    "    yTrain = dfTrain[[\"Survived\"]]\n",
    "    XTest  = dfTest.drop(columns=[\"Survived\"])\n",
    "    yTest  = dfTest[[\"Survived\"]]\n",
    "    return DatasetSplit(\n",
    "        Train=Dataset(X=XTrain, y=yTrain),\n",
    "        Test=Dataset(X=XTest, y=yTest)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "ShowTitleBox(\"EXPLORACI√ìN INICIAL TITANIC DATASET\", color=ConsoleColor.MAGENTA, boxLineStyle= TitleBoxLineStyle.BLOCK)\n",
    "ShowTitleBox(\"CARGANDO EL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "title = \"Data original\"\n",
    "titanicDatasetSplit = LoadTitanicDatasetSplit()\n",
    "ShowDatasetSplitInfo(titanicDatasetSplit, \"Titanic Dataset Split\", headQty=10)\n",
    "\n",
    "\n",
    "CORR_UMBRAL = 0.3\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.ALL, showTable=True, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.STRONG, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.WEAK, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3e7f2",
   "metadata": {},
   "source": [
    "# BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET 1Ô∏è‚É£ Business Understanding - Entender el negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85564ba",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin (Diagnostic) ‚Äî Descripci√≥n de Columnas\n",
    "\n",
    "El dataset contiene medidas computadas a partir de im√°genes digitalizadas de tumores mamarios obtenidos mediante biopsia por aspiraci√≥n con aguja fina (FNA).  \n",
    "Incluye 569 observaciones y 32 columnas.\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Columnas de Identificaci√≥n y Diagn√≥stico\n",
    "\n",
    "### **1. id**\n",
    "Identificador √∫nico del registro. No se utiliza para entrenamiento.\n",
    "\n",
    "### **2. diagnosis**\n",
    "Diagn√≥stico final del tumor:\n",
    "- **M** = Maligno  \n",
    "- **B** = Benigno  \n",
    "\n",
    "Es la **variable objetivo** del dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Variables morfol√≥gicas del tumor\n",
    "\n",
    "Cada variable aparece en tres versiones:\n",
    "\n",
    "- **mean**: valor promedio  \n",
    "- **se**: error est√°ndar  \n",
    "- **worst**: peor valor (percentil 90 o m√°ximo observado)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚≠ê Radius\n",
    "Radio promedio del tumor, calculado como la distancia del centro al borde del n√∫cleo.\n",
    "- radius_mean  \n",
    "- radius_se  \n",
    "- radius_worst  \n",
    "\n",
    "## ‚≠ê Texture\n",
    "Desviaci√≥n est√°ndar de valores de intensidad de pixeles. Describe heterogeneidad.\n",
    "- texture_mean  \n",
    "- texture_se  \n",
    "- texture_worst  \n",
    "\n",
    "## ‚≠ê Perimeter\n",
    "Per√≠metro del n√∫cleo celular.\n",
    "- perimeter_mean  \n",
    "- perimeter_se  \n",
    "- perimeter_worst  \n",
    "\n",
    "## ‚≠ê Area\n",
    "√Årea del n√∫cleo celular, medida en p√≠xeles.\n",
    "- area_mean  \n",
    "- area_se  \n",
    "- area_worst  \n",
    "\n",
    "## ‚≠ê Smoothness\n",
    "Variaci√≥n local del radio. Describe qu√© tan suave o irregular es la forma.\n",
    "- smoothness_mean  \n",
    "- smoothness_se  \n",
    "- smoothness_worst  \n",
    "\n",
    "## ‚≠ê Compactness\n",
    "Calculado como:  \n",
    "`(perimeter¬≤ / area) ‚àí 1.0`  \n",
    "Indica cu√°n compacta es la forma.\n",
    "- compactness_mean  \n",
    "- compactness_se  \n",
    "- compactness_worst  \n",
    "\n",
    "## ‚≠ê Concavity\n",
    "Grado de concavidad del borde del n√∫cleo.\n",
    "- concavity_mean  \n",
    "- concavity_se  \n",
    "- concavity_worst  \n",
    "\n",
    "## ‚≠ê Concave Points\n",
    "N√∫mero de puntos con concavidad en el borde.\n",
    "- concave points_mean  \n",
    "- concave points_se  \n",
    "- concave points_worst  \n",
    "\n",
    "## ‚≠ê Symmetry\n",
    "Mide cu√°n sim√©trica es la forma de la c√©lula.\n",
    "- symmetry_mean  \n",
    "- symmetry_se  \n",
    "- symmetry_worst  \n",
    "\n",
    "## ‚≠ê Fractal Dimension\n",
    "Aproximaci√≥n a la dimensi√≥n fractal del borde celular.\n",
    "- fractal_dimension_mean  \n",
    "- fractal_dimension_se  \n",
    "- fractal_dimension_worst  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204d9e0",
   "metadata": {},
   "source": [
    "# BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET 2Ô∏è‚É£ Data preparation - Preparaci√≥n de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carga el dataset\n",
    "def LoadBreastCancerDataset() -> Dataset:\n",
    "    bc = cast(Bunch, load_breast_cancer(as_frame=True))\n",
    "    df: DataFrame = bc.frame.copy()\n",
    "    TARGET_NAME = \"target\"\n",
    "    X = df.drop(columns=[TARGET_NAME])\n",
    "    NormalizeColumnNames(X)\n",
    "    y = df[[TARGET_NAME]]\n",
    "    y.columns = [\"Diagnosis\"]\n",
    "    return Dataset(X, y)\n",
    "\n",
    "\n",
    "ShowTitleBox(\"BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET\", color=ConsoleColor.MAGENTA, boxLineStyle= TitleBoxLineStyle.BLOCK)\n",
    "ShowTitleBox(\"CARGANDO EL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerDataset = LoadBreastCancerDataset()\n",
    "title = \"Data original\"\n",
    "ShowDatasetInfo(breastCancerDataset, title)\n",
    "\n",
    "ShowTitleBox(\"HACIENDO SPLIT AL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerSplit: DatasetSplit = SplitDataset(breastCancerDataset, trainRatio=0.8)\n",
    "title = \"Split del Dataset\"\n",
    "ShowDatasetSplitHead(breastCancerSplit, title)\n",
    "\n",
    "ShowTitleBox(\"HACIENDO ESCALADO AL SPLIT\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerScaledSplit = ScaleDatasetSplit(breastCancerSplit)\n",
    "title = \"Split escalado\"\n",
    "ShowDatasetSplitHead(breastCancerScaledSplit, title)\n",
    "\n",
    "\n",
    "CORR_UMBRAL = 0.3\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.ALL, showTable=True, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.STRONG, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "ShowDfCorrelation(titanicDatasetSplit.Train.X, \"Titanic TRAIN Data\", level=CorrelationType.WEAK, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
