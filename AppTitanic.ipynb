{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e47d53a",
   "metadata": {},
   "source": [
    "<div style=\"display: table; width: 100%;\">\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 70%;\">\n",
    "    <h1>Herramientas para Data Science</h1>\n",
    "  </div>\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 30%;\">\n",
    "    <img src=\"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/blob/main/Assets/UideLogo.png?raw=true\" alt=\"logo UIDE\" style=\"width:50%;\">\n",
    "  </div>\n",
    "</div>\n",
    "<hr />\n",
    "\n",
    "### üü¶ Componente Pr√°ctico 1  \n",
    "üü° Grupo: 3      \n",
    "üü° Semana: 1      \n",
    "üü° Docente:  Ing. Iv√°n Garc√≠a S., PhD. (idgs78@hotmail.com)     \n",
    "\n",
    "### üü¶ Realizado por:   \n",
    "Estudiantes\n",
    "\n",
    "üíª Evelin Rosero Ordo√±ez   \n",
    "\n",
    "üíª Marjorie Muso Tandalla\n",
    "\n",
    "üíª Jos√© Espinoza Bone\n",
    "\n",
    "### üü¶ Objetivo y alcance del trabajo \n",
    "- Esta pr√°ctica tiene el objetivo de realizar un preprocesamiento de datos y un An√°lisis \n",
    "exploratorio de datos (estad√≠sticas y visualizaci√≥n) de las variables m√°s relevantes \n",
    "que considere para el prop√≥sito de predicci√≥n de supervivencia en el desastre del Titanic. Al finalizar la \n",
    "pr√°ctica, los maestrantes podr√°n manipular adecuadamente un dataset de datos \n",
    "estructurados (alfanum√©ricos). [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\n",
    "\n",
    "- Esta pr√°ctica tiene el objetivo de realizar la predicci√≥n de la supervivencia de los pasajeros del Titanic\n",
    "(sobrevivi√≥ = 1, no sobrevivi√≥ = 0) utilizando los algoritmos de clasificaci√≥n revisados de\n",
    "regresi√≥n log√≠stica y K-NN, as√≠ como realizar la evaluaci√≥n del rendimiento de los algoritmos usando las m√©tricas y gr√°ficas respectivas.\n",
    "Al finalizar la pr√°ctica, los maestrantes podr√°n entender y manipular adecuadamente los diferentes par√°metros e hiperpar√°metros de los algoritmos estudiados.\n",
    "\n",
    "- Esta pr√°ctica tiene el objetivo de realizar la predicci√≥n de la supervivencia de los pasajeros del Titanic\n",
    "(sobrevivi√≥ = 1, no sobrevivi√≥ = 0) utilizando los algoritmos de clasificaci√≥n revisados de\n",
    "√°rbol de decisi√≥n, bosque aleatorio y redes neuronales artificiales, as√≠ como realizar la\n",
    "evaluaci√≥n del rendimiento de los algoritmos usando las m√©tricas y gr√°ficas respectivas.\n",
    "Al finalizar la pr√°ctica, los maestrantes podr√°n entender y manipular adecuadamente los diferentes par√°metros e hiperpar√°metros de los algoritmos estudiados.\n",
    "\n",
    "\n",
    "### üü¶ [C√≥digo fuente original](https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1.git)\n",
    "Con [git](https://git-scm.com/) instalado. En Windows, Linux o MacOS ejecutar el comando.\n",
    "\n",
    "```\n",
    "git clone \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1.git\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bb6d5",
   "metadata": {},
   "source": [
    "# 0Ô∏è‚É£ Preparar entorno\n",
    "\n",
    "Funciones base para utilizar si son requeridas en el presente notebook. Adicional hay funciones utilitarias para utilizar con pandas.DataFrame y finalmente las funciones para cumplir con los objetivos del presente trabajo pr√°ctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIDADES PARA GESTI√ìN DE DEPENDENCIAS E INFORMACI√ìN DEL ENTORNO\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import zipfile\n",
    "from typing import Optional\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "from typing import cast\n",
    "from typing import Tuple\n",
    "from types import SimpleNamespace\n",
    "from typing import Any\n",
    "from typing import Protocol\n",
    "from typing import Literal\n",
    "from typing import Sequence\n",
    "\n",
    "# Libs a instalar\n",
    "LIBS = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"requests\",\n",
    "    \"wcwidth\",\n",
    "    \"tensorflow\"\n",
    "]\n",
    "\n",
    "class ConsoleColor(Enum):\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    BLUE = \"\\033[94m\"\n",
    "    MAGENTA = \"\\033[95m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    WHITE = \"\\033[97m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def PrintColor(message: str, color: ConsoleColor) -> str:\n",
    "    RESET = ConsoleColor.RESET.value\n",
    "    return f\"{color.value}{message}{RESET}\"\n",
    "\n",
    "\n",
    "def ShowMessage(\n",
    "    message: str, title: str, icon: str, color: ConsoleColor, end: str = \"\\n\"\n",
    "):\n",
    "    colored_title = PrintColor(icon + f\"  \" + title.upper() + \":\", color)\n",
    "    print(f\"{colored_title} {message}\", end=end)\n",
    "\n",
    "\n",
    "def ShowInfoMessage(\n",
    "    message: str, title: str = \"Info\", icon: str = \"‚ÑπÔ∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.CYAN, end)\n",
    "\n",
    "\n",
    "def ShowSuccessMessage(\n",
    "    message: str, title: str = \"Success\", icon: str = \"‚úÖ\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.GREEN, end)\n",
    "\n",
    "\n",
    "def ShowErrorMessage(\n",
    "    message: str, title: str = \"Error\", icon: str = \"‚ùå\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.RED, end)\n",
    "\n",
    "\n",
    "def ShowWarningMessage(\n",
    "    message: str, title: str = \"Warning\", icon: str = \"‚ö†Ô∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.YELLOW, end)\n",
    "\n",
    "\n",
    "# Funcion para ejecutar comandos\n",
    "def RunCommand(\n",
    "    commandList: list[str], printCommand: bool = True, printError: bool = True\n",
    ") -> subprocess.CompletedProcess[str]:\n",
    "    print(\"‚è≥\", \" \".join(commandList))\n",
    "\n",
    "    if printCommand:\n",
    "        proc = subprocess.Popen(\n",
    "            commandList,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True,\n",
    "        )\n",
    "\n",
    "        out_lines: list[str] = []\n",
    "        assert proc.stdout is not None\n",
    "        for line in proc.stdout:\n",
    "            print(line, end=\"\")\n",
    "            out_lines.append(line)\n",
    "\n",
    "        proc.wait()\n",
    "        err_text = \"\"\n",
    "        if proc.stderr is not None:\n",
    "            err_text = proc.stderr.read() or \"\"\n",
    "\n",
    "        if proc.returncode != 0 and printError and err_text:\n",
    "            ShowErrorMessage(err_text, \"\", end=\"\")\n",
    "            # print(err_text, end=\"\")\n",
    "\n",
    "        return subprocess.CompletedProcess(\n",
    "            args=commandList,\n",
    "            returncode=proc.returncode,\n",
    "            stdout=\"\".join(out_lines),\n",
    "            stderr=err_text,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        result = subprocess.run(\n",
    "            commandList, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "        if result.returncode != 0 and printError and result.stderr:\n",
    "            ShowErrorMessage(result.stderr, \"\", end=\"\")\n",
    "            # print(result.stderr, end=\"\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# Funci√≥n para instalar las dependencias\n",
    "def InstallDeps(libs: Optional[list[str]] = None):\n",
    "    print(\"‚ÑπÔ∏è Installing deps.\")\n",
    "    printCommand = False\n",
    "    printError = True\n",
    "    RunCommand(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"],\n",
    "        printCommand=printCommand,\n",
    "        printError=printError,\n",
    "    )\n",
    "    if libs is None or libs.count == 0:\n",
    "        print(\"No hay elementos a instalar.\")\n",
    "    else:\n",
    "        RunCommand(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", *libs],\n",
    "            printCommand=printCommand,\n",
    "            printError=printError,\n",
    "        )\n",
    "        print(\"Deps installed.\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar info el ambiente de ejecuci√≥n\n",
    "def ShowEnvironmentInfo():\n",
    "    print(\"‚ÑπÔ∏è  Environment Info:\")\n",
    "    print(\"Python Version:\", sys.version)\n",
    "    print(\"Platform:\", sys.platform)\n",
    "    print(\"Executable Path:\", sys.executable)\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "    print(\"VIRTUAL_ENV:\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "    print(\"sys.prefix:\", sys.prefix)\n",
    "    print(\"sys.base_prefix:\", sys.base_prefix)\n",
    "    print()\n",
    "\n",
    "\n",
    "InstallDeps(LIBS)\n",
    "ShowEnvironmentInfo()\n",
    "import requests\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BoxStyle:\n",
    "    TL: str\n",
    "    TR: str\n",
    "    BL: str\n",
    "    BR: str\n",
    "    H: str\n",
    "    V: str\n",
    "\n",
    "class TitleBoxLineStyle(Enum):\n",
    "    SIMPLE = BoxStyle(\"‚îå\", \"‚îê\", \"‚îî\", \"‚îò\", \"‚îÄ\", \"‚îÇ\")\n",
    "    DOUBLE = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ïê\", \"‚ïë\")\n",
    "    ROUNDED = BoxStyle(\"‚ï≠\", \"‚ïÆ\", \"‚ï∞\", \"‚ïØ\", \"‚îÄ\", \"‚îÇ\")\n",
    "    HEAVY = BoxStyle(\"‚îè\", \"‚îì\", \"‚îó\", \"‚îõ\", \"‚îÅ\", \"‚îÉ\")\n",
    "    ASCII = BoxStyle(\"+\", \"+\", \"+\", \"+\", \"-\", \"|\")\n",
    "    DOUBLE_BOLD = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ï¨\", \"‚ïë\")\n",
    "    BLOCK = BoxStyle(\"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\")\n",
    "    HEAVY_CROSS = BoxStyle(\"‚ïí\", \"‚ïï\", \"‚ïò\", \"‚ïõ\", \"‚ï™\", \"‚îÉ\")\n",
    "    METAL = BoxStyle(\"‚ïû\", \"‚ï°\", \"‚ïò\", \"‚ïõ\", \"‚ïê\", \"‚ïë\")\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar un t√≠tulo con recuadro\n",
    "def ShowTitleBox(\n",
    "    text: str,\n",
    "    max_len: int = 100,\n",
    "    boxLineStyle: TitleBoxLineStyle = TitleBoxLineStyle.SIMPLE,\n",
    "    color: ConsoleColor = ConsoleColor.CYAN,\n",
    "):\n",
    "    try:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            from wcwidth import wcswidth as _w\n",
    "\n",
    "            n = _w(s)\n",
    "            return n if n >= 0 else len(s)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            return len(s)\n",
    "\n",
    "    pad = 1\n",
    "    tlen = vislen(text)\n",
    "    inner = max(max_len, tlen)\n",
    "    left = (inner - tlen) // 2\n",
    "    right = inner - tlen - left\n",
    "\n",
    "    top = f\"{boxLineStyle.value.TL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.TR}\"\n",
    "    mid = f\"{boxLineStyle.value.V}{' ' * pad}{' ' * left}{text}{' ' * right}{' ' * pad}{boxLineStyle.value.V}\"\n",
    "    bot = f\"{boxLineStyle.value.BL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.BR}\"\n",
    "    print(PrintColor(\"\\n\".join([top, mid, bot]), color))\n",
    "\n",
    "\n",
    "# Funci√≥n para descargar un archivo\n",
    "def DownloadFile(uri: str, filename: str, overwrite: bool = False, timeout: int = 20, printInfo: bool = True):\n",
    "    dest = Path(filename).resolve()\n",
    "    if dest.exists() and dest.is_file() and dest.stat().st_size > 0 and not overwrite:\n",
    "        if printInfo:\n",
    "            print(\n",
    "                f'‚úÖ Ya existe: \"{dest}\". No se descarga (use overwrite=True para forzar).'\n",
    "            )\n",
    "        return\n",
    "    if dest.parent and not dest.parent.exists():\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if printInfo:\n",
    "        print(f'‚ÑπÔ∏è Descargando \"{uri}\" ‚Üí \"{dest}\"')\n",
    "    try:\n",
    "        with requests.get(uri, stream=True, timeout=timeout) as resp:\n",
    "            resp.raise_for_status()\n",
    "            tmp = dest.with_suffix(dest.suffix + \".part\")\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(chunk_size=1024 * 64):\n",
    "                    if chunk:  # filtra keep-alive chunks\n",
    "                        f.write(chunk)\n",
    "            tmp.replace(dest)\n",
    "        if printInfo: \n",
    "            print(f'‚úÖ Archivo \"{dest}\" descargado exitosamente.')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error al descargar: {e}\")\n",
    "\n",
    "\n",
    "# Funci√≥n para descomprimir un archivo zip\n",
    "def UnzipFile(filename: str, outputDir: str):\n",
    "    print(f'‚ÑπÔ∏è Descomprimiendo \"{filename}\" en \"{outputDir}\"')\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(outputDir)\n",
    "        print(f\"Descomprimido en: {os.path.abspath(outputDir)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIDADES PARA AN√ÅLISIS Y MANIPULACI√ìN DE DATAFRAMES\n",
    "\n",
    "# Importar libraries\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurar opciones de Pandas\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pandas.set_option(\"display.max_rows\", None)\n",
    "pandas.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la informaci√≥n del DataFrame.\n",
    "def ShowDfInfo(df: pandas.DataFrame, title):\n",
    "    display(f\"‚ÑπÔ∏è INFO {title} ‚ÑπÔ∏è\")\n",
    "    df.info()\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n primeras filas del DataFrame.\n",
    "def ShowDfHead(df: pandas.DataFrame, title: str, headQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: Primeros {headQty} elementos.\")\n",
    "    display(df.head(headQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n √∫ltimas filas del DataFrame.\n",
    "def ShowDfTail(df: pandas.DataFrame, title: str, tailQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: √öltimos {tailQty} elementos.\")\n",
    "    display(df.tail(tailQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Mostrar el tama√±o del DataFrame\n",
    "def ShowDfShape(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è {title} - Tama√±o de los datos\")\n",
    "    display(f\"{df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la estad√≠stica descriptiva de todas las columnas del DataFrame, por tipo de dato.\n",
    "def ShowDfStats(df: pandas.DataFrame, title: str = \"\"):\n",
    "    display(f\"‚ÑπÔ∏è Estad√≠stica descriptiva - {title}\")\n",
    "    numeric_cols = df.select_dtypes(include=\"number\")\n",
    "    if not numeric_cols.empty:\n",
    "        display(\"    üî¢ Columnas num√©ricas\".upper())\n",
    "        numeric_desc = (\n",
    "            numeric_cols.describe().round(2).T\n",
    "        )  # Transpuesta para a√±adir columna\n",
    "        numeric_desc[\"var\"] = numeric_cols.var(numeric_only=True).round(2)\n",
    "        display(numeric_desc.T)\n",
    "    non_numeric_cols = df.select_dtypes(\n",
    "        include=[\"boolean\", \"string\", \"category\", \"object\"]\n",
    "    )\n",
    "    if not non_numeric_cols.empty:\n",
    "        display(\"    üî° Columnas no num√©ricas\".upper())\n",
    "        non_numeric_desc = non_numeric_cols.describe()\n",
    "        display(non_numeric_desc)\n",
    "    datetime_cols = df.select_dtypes(include=[\"datetime\", \"datetimetz\"])\n",
    "    if not datetime_cols.empty:\n",
    "        display(\"    üìÖ Columnas fechas\".upper())\n",
    "        datetime_desc = datetime_cols.describe()\n",
    "        display(datetime_desc)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar una visi√≥n general completa del DataFrame\n",
    "def ShowFullDfOverview(df, title, headQty=5, tailQty=5):\n",
    "    ShowDfInfo(df, title)\n",
    "    ShowDfStats(df, title)\n",
    "    ShowDfShape(df, title)\n",
    "    ShowDfHead(df, title, headQty=headQty)\n",
    "    ShowDfTail(df, title, tailQty=tailQty)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar los valores nulos o NaN de cada columna en un DataFrame\n",
    "def ShowDfNanValues(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è Contador de valores Nulos - {title}\")\n",
    "    nulls_count = df.isnull().sum()\n",
    "    nulls_df = nulls_count.reset_index()\n",
    "    nulls_df.columns = [\"Columna\", \"Cantidad_Nulos\"]\n",
    "    display(nulls_df)\n",
    "    display()\n",
    "\n",
    "\n",
    "# Tipos de correlaci√≥n\n",
    "class CorrelationType(Enum):\n",
    "    ALL = \"all\"\n",
    "    STRONG = \"strong\"\n",
    "    WEAK = \"weak\"\n",
    "\n",
    "\n",
    "# Muestra las correlaciones completas, d√©biles y fuertes.\n",
    "def ShowDfCorrelation(\n",
    "    df: pandas.DataFrame,\n",
    "    title: str,\n",
    "    fig: Optional[Figure] = None,\n",
    "    ax: Optional[Axes] = None,\n",
    "    level: CorrelationType = CorrelationType.ALL,\n",
    "    umbral: float = 0.6,\n",
    "    showTable: bool = False,\n",
    "    figsize: tuple = (8, 6),\n",
    "    annotate: bool = True,\n",
    "):\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    display(f\"‚ÑπÔ∏è {(title).upper()} - Matriz de Correlaci√≥n, Type: {level.name}\")\n",
    "\n",
    "    corr = df.select_dtypes(include=[\"number\"]).corr().copy()\n",
    "\n",
    "    if level == CorrelationType.STRONG:\n",
    "        corr = corr.where(np.abs(corr) >= umbral)\n",
    "    elif level == CorrelationType.WEAK:\n",
    "        corr = corr.where(np.abs(corr) < umbral)\n",
    "        np.fill_diagonal(corr.values, 1)\n",
    "    elif level != CorrelationType.ALL:\n",
    "        raise ValueError(f\"Invalid level: {level}\")\n",
    "\n",
    "    cax = ax.matshow(corr, vmin=-1, vmax=1)\n",
    "\n",
    "    cols = corr.columns\n",
    "    ax.set_xticks(range(len(cols)))\n",
    "    ax.set_yticks(range(len(cols)))\n",
    "    ax.set_xticklabels(cols, rotation=90, ha=\"left\")\n",
    "    ax.set_yticklabels(cols)\n",
    "\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    if annotate:\n",
    "        for (i, j), value in np.ndenumerate(corr.values):\n",
    "            if not np.isnan(value):\n",
    "                ax.text(j, i, f\"{value:+.2f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    if level == CorrelationType.ALL:\n",
    "        titulo = \"Matriz de correlaci√≥n completa\"\n",
    "    else:\n",
    "        titulo = f\"Matriz de correlaci√≥n ({level.name}, umbral={umbral})\"\n",
    "\n",
    "    total_elementos = corr.size\n",
    "    total_nodiagonal = corr.size - corr.shape[0]\n",
    "    total_nan = corr.isna().sum().sum()\n",
    "    total_validos = total_elementos - total_nan - corr.shape[0]\n",
    "\n",
    "    titulo = (\n",
    "        f\"{titulo}, Total Matriz: {total_nodiagonal}, \"\n",
    "        f\"Total v√°lidos: {total_validos} ({((total_validos * 100) / total_nodiagonal):.2f}%)\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(titulo, pad=20)\n",
    "    ax.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if showTable:\n",
    "        display(corr)\n",
    "    fig.show()\n",
    "    return fig, corr\n",
    "\n",
    "\n",
    "def NormalizeColumnNames(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    df.columns = [\n",
    "        col.strip().title().replace(\" \", \"\").replace(\"_\", \"\") for col in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def DropColumns(\n",
    "    df: pandas.DataFrame, toDrop: list[str], inplace: bool = False\n",
    ") -> pandas.DataFrame:\n",
    "    if not toDrop:\n",
    "        return df\n",
    "    if inplace:\n",
    "        df.drop(columns=df.columns.intersection(toDrop), inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        return df.drop(columns=df.columns.intersection(toDrop))\n",
    "\n",
    "\n",
    "# Para almacenar los datos del dataset\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    X: pandas.DataFrame\n",
    "    y: pandas.DataFrame\n",
    "\n",
    "\n",
    "# Para almacenar los datos de split del dataset.\n",
    "@dataclass\n",
    "class DatasetSplit:\n",
    "    Train: Dataset\n",
    "    Test: Dataset\n",
    "\n",
    "\n",
    "# Muestra el head de cada componente del split.\n",
    "def ShowDatasetSplitHead(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    ShowDfHead(split.Train.X, f\"{title} - X Train\", headQty)\n",
    "    ShowDfHead(split.Train.y, f\"{title} - y Train\", headQty)\n",
    "    ShowDfHead(split.Test.X, f\"{title} - X Test\", headQty)\n",
    "    ShowDfHead(split.Test.y, f\"{title} - y Test\", headQty)\n",
    "\n",
    "\n",
    "# Muestra la informaci√≥n del Dataset\n",
    "def ShowDatasetInfo(data: Dataset, title):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - Caracteristicas - X\"\n",
    "    ShowDfInfo(data.X, title)\n",
    "    ShowDfShape(data.X, title)\n",
    "    ShowDfStats(data.X, title)\n",
    "    ShowDfNanValues(data.X, title)\n",
    "    ShowDfHead(data.X, title)\n",
    "    ShowDfTail(data.X, title)\n",
    "    title = f\"{tAux} - Caracter√≠sticas - y\"\n",
    "    ShowDfInfo(data.y, title)\n",
    "    ShowDfShape(data.y, title)\n",
    "    ShowDfStats(data.y, title)\n",
    "    ShowDfNanValues(data.y, title)\n",
    "    ShowDfHead(data.y, title)\n",
    "    ShowDfTail(data.y, title)\n",
    "\n",
    "\n",
    "# Muestra la informaci√≥n del Dataset Split\n",
    "def ShowDatasetSplitInfo(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - TRAIN\"\n",
    "    ShowDatasetInfo(split.Train, title)\n",
    "    title = f\"{tAux} - TEST\"\n",
    "    ShowDatasetInfo(split.Test, title)\n",
    "\n",
    "\n",
    "# Realiza el split del Dataset, en Train y test utilizando el ratio.\n",
    "def SplitDataset(\n",
    "    data: Dataset, trainRatio: float = 0.8, randomState: int = 42\n",
    ") -> DatasetSplit:\n",
    "    y_strat = data.y.iloc[:, 0]\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(\n",
    "        data.X,\n",
    "        data.y,\n",
    "        train_size=trainRatio,\n",
    "        random_state=randomState,\n",
    "        stratify=y_strat,\n",
    "    )\n",
    "    return DatasetSplit(\n",
    "        Train=Dataset(X=XTrain.reset_index(drop=True), y=yTrain.reset_index(drop=True)),\n",
    "        Test=Dataset(X=XTest.reset_index(drop=True), y=yTest.reset_index(drop=True)),\n",
    "    )\n",
    "\n",
    "\n",
    "# Contrato para los escaladores\n",
    "class ScalerProtocol(Protocol):\n",
    "    def fit(self, X, y: Any = None) -> Any: ...\n",
    "    def transform(self, X) -> Any: ...\n",
    "    def fit_transform(self, X, y: Any = None) -> Any: ...\n",
    "\n",
    "\n",
    "# Para almacenar los datos del dataset aplicado el escalador.\n",
    "@dataclass\n",
    "class ScaledDatasetSplit(DatasetSplit):\n",
    "    Scaler: ScalerProtocol\n",
    "\n",
    "# Enum para los tipos de escaladores soportados\n",
    "class ScalerType(Enum):\n",
    "    STANDARD = \"Standard\"\n",
    "    MIN_MAX = \"minmax\"\n",
    "    ROBUST = \"robust\"\n",
    "    MAX_ABS = \"maxabs\"\n",
    "    NORMALIZER = \"normalizer\"\n",
    "    QUANTILE = \"quantile\"\n",
    "    POWER = \"power\"\n",
    "    FUNCTION = \"function\"\n",
    "\n",
    "\n",
    "\n",
    "# Crea una instancia de scaler seg√∫n el Enum ScalerType.\n",
    "def CreateScaler(scalerType: ScalerType, **kwargs) -> ScalerProtocol:\n",
    "    if scalerType == ScalerType.STANDARD:\n",
    "        return StandardScaler(**kwargs)\n",
    "    if scalerType == ScalerType.MIN_MAX:\n",
    "        return MinMaxScaler(**kwargs)\n",
    "    if scalerType == ScalerType.ROBUST:\n",
    "        return RobustScaler(**kwargs)\n",
    "    if scalerType == ScalerType.MAX_ABS:\n",
    "        return MaxAbsScaler(**kwargs)\n",
    "    if scalerType == ScalerType.NORMALIZER:\n",
    "        return Normalizer(**kwargs)\n",
    "    if scalerType == ScalerType.QUANTILE:\n",
    "        return QuantileTransformer(**kwargs)\n",
    "    if scalerType == ScalerType.POWER:\n",
    "        return PowerTransformer(**kwargs)\n",
    "    if scalerType == ScalerType.FUNCTION:\n",
    "        return FunctionTransformer(**kwargs)\n",
    "    raise ValueError(f\"ScalerType no soportado: {scalerType}\")\n",
    "\n",
    "def DetectScaler(scaler: ScalerProtocol) -> ScalerType:\n",
    "    if isinstance(scaler, StandardScaler):\n",
    "        return ScalerType.STANDARD\n",
    "    if isinstance(scaler, MinMaxScaler):\n",
    "        return ScalerType.MIN_MAX\n",
    "    if isinstance(scaler, RobustScaler):\n",
    "        return ScalerType.ROBUST\n",
    "    if isinstance(scaler, MaxAbsScaler):\n",
    "        return ScalerType.MAX_ABS\n",
    "    if isinstance(scaler, Normalizer):\n",
    "        return ScalerType.NORMALIZER\n",
    "    if isinstance(scaler, QuantileTransformer):\n",
    "        return ScalerType.QUANTILE\n",
    "    if isinstance(scaler, PowerTransformer):\n",
    "        return ScalerType.POWER\n",
    "    if isinstance(scaler, FunctionTransformer):\n",
    "        return ScalerType.FUNCTION\n",
    "    raise ValueError(f\"No se reconoce el tipo de scaler: {type(scaler)}\")\n",
    "\n",
    "# Escala el split usando el escalador proporcionado y retorna el split escalado.\n",
    "def ScaleDatasetSplit(\n",
    "    split: DatasetSplit, scaler: ScalerProtocol = StandardScaler()\n",
    ") -> ScaledDatasetSplit:\n",
    "    XTrainScaledValues = scaler.fit_transform(split.Train.X)\n",
    "    XTestScaledValues = scaler.transform(split.Test.X)\n",
    "\n",
    "    XTrainScaled = pandas.DataFrame(\n",
    "        XTrainScaledValues, columns=split.Train.X.columns, index=split.Train.X.index\n",
    "    )\n",
    "\n",
    "    XTestScaled = pandas.DataFrame(\n",
    "        XTestScaledValues, columns=split.Test.X.columns, index=split.Test.X.index\n",
    "    )\n",
    "\n",
    "    TrainScaledDataset = Dataset(X=XTrainScaled, y=split.Train.y.copy())\n",
    "    TestScaledDataset = Dataset(X=XTestScaled, y=split.Test.y.copy())\n",
    "\n",
    "    return ScaledDatasetSplit(\n",
    "        Train=TrainScaledDataset, Test=TestScaledDataset, Scaler=scaler\n",
    "    )\n",
    "\n",
    "# Para almacenar los datos del dataset aplicado PCA.\n",
    "@dataclass\n",
    "class PcaDatasetSplit(DatasetSplit):\n",
    "    Pca: PCA\n",
    "    Scaler: ScalerProtocol | None = None \n",
    "\n",
    "# Aplica PCA al split escalado y retorna el split con PCA aplicado.\n",
    "def ApplyPCA(\n",
    "    split: ScaledDatasetSplit,\n",
    "    explainedVarianceRatioSum: float = 0.95,\n",
    "    randomState: int = 42\n",
    ") -> PcaDatasetSplit:\n",
    "\n",
    "    def GetPCNames(n: int) -> list[str]:\n",
    "        return [f\"PC{i}\" for i in range(1, n + 1)]\n",
    "\n",
    "    pca = PCA(n_components=explainedVarianceRatioSum, random_state=randomState)\n",
    "\n",
    "    XTrainPCA = pca.fit_transform(split.Train.X)\n",
    "    XTestPCA = pca.transform(split.Test.X)\n",
    "\n",
    "    XTrainPcaDf = pandas.DataFrame(\n",
    "        XTrainPCA, index=split.Train.X.index, columns=GetPCNames(XTrainPCA.shape[1])\n",
    "    )\n",
    "\n",
    "    XTestPcaDf = pandas.DataFrame(\n",
    "        XTestPCA, index=split.Test.X.index, columns=GetPCNames(XTestPCA.shape[1])\n",
    "    )\n",
    "\n",
    "    return PcaDatasetSplit(\n",
    "        Train=Dataset(X=XTrainPcaDf, y=split.Train.y.copy()),\n",
    "        Test=Dataset(X=XTestPcaDf, y=split.Test.y.copy()),\n",
    "        Pca=pca,\n",
    "        Scaler=split.Scaler\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "SplitLike = ScaledDatasetSplit | PcaDatasetSplit\n",
    "\n",
    "# Para almacenar los resultados de la regresi√≥n log√≠stica\n",
    "@dataclass\n",
    "class LogisticRegressionResult:\n",
    "    Model: LogisticRegression\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Iters: list[int] | np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "\n",
    "# Aplica regresi√≥n log√≠stica al split escalado y retorna el resultado.\n",
    "def ApplyLogisticRegression(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    randomState: int = 42,\n",
    "    maxIter: int = 200,\n",
    "    C: float = 1.0,\n",
    "    penalty: Literal['l1', 'l2', 'elasticnet'] | None = \"l2\",\n",
    "    solver: Literal['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'] = \"lbfgs\"\n",
    ") -> LogisticRegressionResult:\n",
    "    \n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=maxIter,\n",
    "        random_state=randomState,\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPredTrain = model.predict(XTrain)\n",
    "    yPredTest = model.predict(XTest)\n",
    "\n",
    "    yProbaTrain = model.predict_proba(XTrain)\n",
    "    yProbaTest = model.predict_proba(XTest)\n",
    "\n",
    "    dfProbaTest = pandas.DataFrame(\n",
    "        yProbaTest,\n",
    "        index=XTest.index,\n",
    "        columns=[f\"Class-{cls}-Prob\" for cls in model.classes_]\n",
    "    )\n",
    "\n",
    "    dfPredTest = pandas.DataFrame(\n",
    "        {\n",
    "            \"yReal\": yTest.values,\n",
    "            \"yPred\": yPredTest\n",
    "        },\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPredTest = pandas.concat([dfPredTest, dfProbaTest], axis=1)\n",
    "\n",
    "    acc = accuracy_score(yTest, yPredTest)\n",
    "    prec = precision_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    cm = confusion_matrix(yTest, yPredTest)\n",
    "    report = classification_report(yTest, yPredTest)\n",
    "\n",
    "    return LogisticRegressionResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPredTest,\n",
    "        Accuracy=float(acc),\n",
    "        ConfusionMatrix=cm,\n",
    "        Precision=float(prec),\n",
    "        Recall=float(rec),\n",
    "        F1=float(f1),\n",
    "        Iters=model.n_iter_,\n",
    "        Report=str(report),\n",
    "        Target=targetColumn\n",
    "    )\n",
    "\n",
    "# Para almacenar los resultados de KNN\n",
    "@dataclass\n",
    "class KnnResult:\n",
    "    Model: KNeighborsClassifier\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "    K: int\n",
    "\n",
    "def GetBestKForKNN(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    kMax: int = 30\n",
    ") -> int:\n",
    "    \n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    bestK = 1\n",
    "    bestScore = -1.0\n",
    "\n",
    "    for k in range(1, kMax + 1):\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(XTrain, yTrain)\n",
    "\n",
    "        yPred = model.predict(XTest)\n",
    "        acc = accuracy_score(yTest, yPred)\n",
    "\n",
    "        if acc > bestScore:\n",
    "            bestScore = acc\n",
    "            bestK = k\n",
    "    return bestK\n",
    "\n",
    "def ApplyKNN(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    weights: Literal[\"uniform\", \"distance\"] = \"uniform\",\n",
    "    metric: Literal[\n",
    "        \"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"\n",
    "    ] = \"minkowski\"\n",
    ") -> KnnResult:\n",
    "    K = GetBestKForKNN(split, targetColumn)\n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=K,\n",
    "        weights=weights,\n",
    "        metric=metric\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPred = model.predict(XTest)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        yProba = model.predict_proba(XTest)\n",
    "        dfProba = pandas.DataFrame(\n",
    "            yProba,\n",
    "            index=XTest.index,\n",
    "            columns=[f\"Class-{cls}-Prob\" for cls in model.classes_],\n",
    "        )\n",
    "    else:\n",
    "        dfProba = pandas.DataFrame(index=XTest.index)\n",
    "\n",
    "    dfPred = pandas.DataFrame(\n",
    "        {\n",
    "            \"yReal\": yTest.values,\n",
    "            \"yPred\": yPred,\n",
    "        },\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPred = pandas.concat([dfPred, dfProba], axis=1)\n",
    "\n",
    "    acc = accuracy_score(yTest, yPred)\n",
    "    prec = precision_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    cm = confusion_matrix(yTest, yPred)\n",
    "    report = classification_report(yTest, yPred)\n",
    "\n",
    "    return KnnResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPred,\n",
    "        Accuracy=float(acc),\n",
    "        Precision=float(prec),\n",
    "        Recall=float(rec),\n",
    "        F1=float(f1),\n",
    "        ConfusionMatrix=cm,\n",
    "        Report=str(report),\n",
    "        Target=targetColumn,\n",
    "        K=K\n",
    "    )\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "@dataclass\n",
    "class RandomForestResult:\n",
    "    Model: RandomForestClassifier\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "\n",
    "def ApplyRandomForest(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int | None = None,\n",
    "    criterion: Literal[\"gini\", \"entropy\", \"log_loss\"] = \"gini\",\n",
    "    randomState: int = 42\n",
    ") -> RandomForestResult:\n",
    "\n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        criterion=criterion,\n",
    "        random_state=randomState\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPred = model.predict(XTest)\n",
    "    yProba = model.predict_proba(XTest)\n",
    "\n",
    "    dfPred = pandas.DataFrame(\n",
    "        {\"yReal\": yTest.values, \"yPred\": yPred},\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfProba = pandas.DataFrame(\n",
    "        yProba,\n",
    "        columns=[f\"Class-{cls}-Prob\" for cls in model.classes_],\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPred = pandas.concat([dfPred, dfProba], axis=1)\n",
    "\n",
    "    return RandomForestResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPred,\n",
    "        Accuracy=float(accuracy_score(yTest, yPred)),\n",
    "        Precision=float(precision_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        Recall=float(recall_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        F1=float(f1_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        ConfusionMatrix=confusion_matrix(yTest, yPred),\n",
    "        Report=str(classification_report(yTest, yPred)),\n",
    "        Target=targetColumn\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DecisionTreeResult:\n",
    "    Model: DecisionTreeClassifier\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "\n",
    "def ApplyDecisionTree(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    max_depth: int | None = None,\n",
    "    criterion: Literal[\"gini\", \"entropy\", \"log_loss\"] = \"gini\",\n",
    "    randomState: int = 42\n",
    ") -> DecisionTreeResult:\n",
    "\n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        criterion=criterion,\n",
    "        random_state=randomState\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPred = model.predict(XTest)\n",
    "    yProba = model.predict_proba(XTest)\n",
    "\n",
    "    dfPred = pandas.DataFrame(\n",
    "        {\"yReal\": yTest.values, \"yPred\": yPred},\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfProba = pandas.DataFrame(\n",
    "        yProba,\n",
    "        columns=[f\"Class-{cls}-Prob\" for cls in model.classes_],\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPred = pandas.concat([dfPred, dfProba], axis=1)\n",
    "\n",
    "    return DecisionTreeResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPred,\n",
    "        Accuracy=float(accuracy_score(yTest, yPred)),\n",
    "        Precision=float(precision_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        Recall=float(recall_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        F1=float(f1_score(yTest, yPred, average=\"weighted\", zero_division=0)),\n",
    "        ConfusionMatrix=confusion_matrix(yTest, yPred),\n",
    "        Report=str(classification_report(yTest, yPred)),\n",
    "        Target=targetColumn\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class RNAResult:\n",
    "    Model: Sequential\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "\n",
    "def ApplyRNA(\n",
    "    split: SplitLike,\n",
    "    targetColumn: str,\n",
    "    epochs: int = 100,\n",
    "    batchSize: int = 32,\n",
    "    learningRate: float = 1e-3,\n",
    "    patience: int = 10\n",
    ") -> RNAResult:\n",
    "\n",
    "    XTrain = split.Train.X.to_numpy(dtype=np.float64)\n",
    "    XTest  = split.Test.X.to_numpy(dtype=np.float64)\n",
    "    yTrain = split.Train.y[targetColumn].to_numpy(dtype=np.int64)\n",
    "    yTest  = split.Test.y[targetColumn].to_numpy(dtype=np.int64)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(10, activation=\"relu\", input_dim=XTrain.shape[1]),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learningRate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        XTrain, yTrain,\n",
    "        epochs=epochs,\n",
    "        batch_size=batchSize,\n",
    "        validation_data=(XTest, yTest),\n",
    "        callbacks=[earlyStopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    yProba = model.predict(XTest).ravel()\n",
    "    yPred = (yProba > 0.5).astype(int)\n",
    "\n",
    "    dfPred = pandas.DataFrame(\n",
    "        {\n",
    "            \"yReal\": yTest,\n",
    "            \"yPred\": yPred,\n",
    "            \"Class-1-Prob\": yProba\n",
    "        },\n",
    "        index=split.Test.X.index\n",
    "    )\n",
    "\n",
    "    return RNAResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPred,\n",
    "        Accuracy=float(accuracy_score(yTest, yPred)),\n",
    "        Precision=float(precision_score(yTest, yPred, zero_division=0)),\n",
    "        Recall=float(recall_score(yTest, yPred, zero_division=0)),\n",
    "        F1=float(f1_score(yTest, yPred, zero_division=0)),\n",
    "        ConfusionMatrix=confusion_matrix(yTest, yPred),\n",
    "        Report=str(classification_report(yTest, yPred)),\n",
    "        Target=targetColumn\n",
    "    )\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def GenerateMetricsTable(\n",
    "    splitList: list[SplitLike],\n",
    "    targetColumn: str,\n",
    "    includeRNA: bool = True\n",
    ") -> pandas.DataFrame:\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, split in enumerate(splitList, start=1):\n",
    "\n",
    "        splitType = \"PCA\" if isinstance(split, PcaDatasetSplit) else \"SCALED\"\n",
    "        scalerName = DetectScaler(split.Scaler).value\n",
    "\n",
    "        # Modelos\n",
    "        lr  = ApplyLogisticRegression(split, targetColumn)\n",
    "        knn = ApplyKNN(split, targetColumn)\n",
    "        dt  = ApplyDecisionTree(split, targetColumn)\n",
    "        rf  = ApplyRandomForest(split, targetColumn)\n",
    "\n",
    "        row = {\n",
    "            \"Index\": idx,\n",
    "            \"Type\": splitType,\n",
    "            \"Scaler\": scalerName,\n",
    "\n",
    "            # Logistic Regression\n",
    "            \"LR_Accuracy\": lr.Accuracy,\n",
    "            \"LR_F1\": lr.F1,\n",
    "\n",
    "            # KNN\n",
    "            \"KNN_K\": knn.K,\n",
    "            \"KNN_Accuracy\": knn.Accuracy,\n",
    "            \"KNN_F1\": knn.F1,\n",
    "\n",
    "            # Decision Tree\n",
    "            \"DT_Accuracy\": dt.Accuracy,\n",
    "            \"DT_F1\": dt.F1,\n",
    "\n",
    "            # Random Forest\n",
    "            \"RF_Accuracy\": rf.Accuracy,\n",
    "            \"RF_F1\": rf.F1,\n",
    "        }\n",
    "\n",
    "        if includeRNA:\n",
    "            rna = ApplyRNA(split, targetColumn)\n",
    "            row.update({\n",
    "                \"RNA_Accuracy\": rna.Accuracy,\n",
    "                \"RNA_F1\": rna.F1\n",
    "            })\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    return pandas.DataFrame(results)\n",
    "\n",
    "# Funci√≥n para graficar la matriz de confusi√≥n\n",
    "def PlotConfusionMatrix(\n",
    "    cm,\n",
    "    classNames: Sequence[str] | None = None,\n",
    "    title: str = \"Confusion Matrix\"\n",
    "):\n",
    "    # Si classNames es None ‚Üí usar \"auto\"\n",
    "    xticks = classNames if classNames is not None else \"auto\"\n",
    "    yticks = classNames if classNames is not None else \"auto\"\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=xticks,\n",
    "        yticklabels=yticks\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Utilidades para detecci√≥n de tipos de split\n",
    "@dataclass(frozen=True)\n",
    "class SplitTypeInfo:\n",
    "    IsPCA: bool\n",
    "    IsScaled: bool\n",
    "    IsRaw: bool\n",
    "\n",
    "# Detecta el tipo de split (PCA, Escalado, Crudo)\n",
    "def DetectSplitType(split) -> SplitTypeInfo:\n",
    "    isPca = isinstance(split, PcaDatasetSplit)\n",
    "    isScaled = isinstance(split, ScaledDatasetSplit)\n",
    "    isRaw = not isPca and not isScaled\n",
    "\n",
    "    return SplitTypeInfo(\n",
    "        IsPCA=isPca,\n",
    "        IsScaled=isScaled,\n",
    "        IsRaw=isRaw\n",
    "    )\n",
    "\n",
    "def PlotAccuracyBySplit(\n",
    "    dfMetrics: pandas.DataFrame,\n",
    "    title: str = \"Accuracy por Modelo y Split\"\n",
    "):\n",
    "    # Modelos y columnas asociadas\n",
    "    modelCols = {\n",
    "        \"LR\": \"LR_Accuracy\",\n",
    "        \"KNN\": \"KNN_Accuracy\",\n",
    "        \"DT\": \"DT_Accuracy\",\n",
    "        \"RF\": \"RF_Accuracy\",\n",
    "        \"RNA\": \"RNA_Accuracy\",\n",
    "    }\n",
    "\n",
    "    # N√∫mero de splits\n",
    "    nSplits = dfMetrics.shape[0]\n",
    "    splitLabels = [f\"Split {i+1}\" for i in range(nSplits)]\n",
    "\n",
    "    models = list(modelCols.keys())\n",
    "    nModels = len(models)\n",
    "\n",
    "    x = np.arange(nModels)\n",
    "    width = 0.8 / nSplits  # ancho din√°mico\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for i in range(nSplits):\n",
    "        accuracies = [\n",
    "            dfMetrics.loc[i, col]\n",
    "            for col in modelCols.values()\n",
    "        ]\n",
    "\n",
    "        plt.bar(\n",
    "            x + i * width,\n",
    "            accuracies,\n",
    "            width,\n",
    "            label=splitLabels[i]\n",
    "        )\n",
    "\n",
    "    plt.xticks(x + width * (nSplits - 1) / 2, models)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Splits\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _PrintModelMetrics(\n",
    "    result,\n",
    "    showConfusionMatrix: bool = True\n",
    "):\n",
    "    print(f\"Accuracy : {result.Accuracy:.4f}\")\n",
    "    print(f\"Precision: {result.Precision:.4f}\")\n",
    "    print(f\"Recall   : {result.Recall:.4f}\")\n",
    "    print(f\"F1 Score : {result.F1:.4f}\")\n",
    "\n",
    "    if showConfusionMatrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        PlotConfusionMatrix(\n",
    "            result.ConfusionMatrix,\n",
    "            classNames=None,\n",
    "            title=\"Confusion Matrix\"\n",
    "        )\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(result.Report)\n",
    "\n",
    "def EvaluateDatasetSplits(\n",
    "    splitList: list[SplitLike],\n",
    "    targetColumn: str,\n",
    "    includeRNA: bool = True,\n",
    "    showConfusionMatrix: bool = True\n",
    "):\n",
    "    for idx, split in enumerate(splitList, start=1):\n",
    "\n",
    "        splitType = \"PCA\" if isinstance(split, PcaDatasetSplit) else \"SCALED\"\n",
    "        scalerName = DetectScaler(split.Scaler).value\n",
    "\n",
    "        header = (\n",
    "            f\"SPLIT {idx} | Type={splitType} | \"\n",
    "            f\"Scaler={scalerName} | \"\n",
    "            f\"Features={split.Train.X.shape[1]}\"\n",
    "        )\n",
    "        ShowTitleBox(f\"EVALUACI√ìN DE MODELOS - {header}\", color=ConsoleColor.MAGENTA, boxLineStyle= TitleBoxLineStyle.BLOCK)\n",
    "\n",
    "        print(\"\\nüîπ LOGISTIC REGRESSION\")\n",
    "        lr = ApplyLogisticRegression(split, targetColumn)\n",
    "        _PrintModelMetrics(lr, showConfusionMatrix)\n",
    "\n",
    "        print(\"\\nüîπ KNN\")\n",
    "        knn = ApplyKNN(split, targetColumn)\n",
    "        print(f\"Best K: {knn.K}\")\n",
    "        _PrintModelMetrics(knn, showConfusionMatrix)\n",
    "\n",
    "        print(\"\\nüîπ DECISION TREE\")\n",
    "        dt = ApplyDecisionTree(split, targetColumn)\n",
    "        _PrintModelMetrics(dt, showConfusionMatrix)\n",
    "\n",
    "        print(\"\\nüîπ RANDOM FOREST\")\n",
    "        rf = ApplyRandomForest(split, targetColumn)\n",
    "        _PrintModelMetrics(rf, showConfusionMatrix)\n",
    "\n",
    "        if includeRNA:\n",
    "            print(\"\\nüîπ RNA (Red Neuronal Artificial)\")\n",
    "            rna = ApplyRNA(split, targetColumn)\n",
    "            _PrintModelMetrics(rna, showConfusionMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce2840",
   "metadata": {},
   "source": [
    "# TITANIC DATASET 1Ô∏è‚É£ Business Understanding - Entender el negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16432a0",
   "metadata": {},
   "source": [
    "| Columna         | Descripci√≥n                                                                                                                                                  |\n",
    "| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **PassengerId** | Identificador √∫nico asignado a cada pasajero en el dataset. No tiene significado real en el viaje, solo sirve como √≠ndice.                                   |\n",
    "| **Survived**    | Indica si el pasajero **sobrevivi√≥ (1)** o **muri√≥ (0)**. Es la variable objetivo en la mayor√≠a de proyectos de Machine Learning sobre este dataset.         |\n",
    "| **Pclass**      | Clase del boleto del pasajero: **1 = Primera clase**, **2 = Segunda clase**, **3 = Tercera clase**. Representa una medida indirecta de nivel socioecon√≥mico. |\n",
    "| **Name**        | Nombre completo del pasajero, generalmente incluye tratamiento o t√≠tulo social (Mr., Mrs., Miss, etc.).                                                      |\n",
    "| **Sex**         | Sexo del pasajero: **male** (hombre) o **female** (mujer).                                                                                                   |\n",
    "| **Age**         | Edad del pasajero en a√±os. Puede contener valores faltantes. Los ni√±os peque√±os pueden aparecer con valores decimales.                                       |\n",
    "| **SibSp**       | N√∫mero de **hermanos (siblings)** y **c√≥nyuges (spouses)** que viajaban con el pasajero en el Titanic.                                                       |\n",
    "| **Parch**       | N√∫mero de **padres (parents)** e **hijos (children)** que viajaban con el pasajero.                                                                          |\n",
    "| **Ticket**      | C√≥digo del boleto del pasajero. Puede incluir letras y n√∫meros; no cumple un formato est√°ndar.                                                               |\n",
    "| **Fare**        | Tarifa pagada por el pasajero por su boleto. El valor depende de la clase y otras condiciones del viaje.                                                     |\n",
    "| **Cabin**       | N√∫mero de cabina asignada. Muchos valores est√°n vac√≠os porque la mayor√≠a de pasajeros no ten√≠a cabina asignada (especialmente en 3ra clase).                 |\n",
    "| **Embarked**    | Puerto de embarque: **C = Cherbourg**, **Q = Queenstown**, **S = Southampton**.                                                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7516605",
   "metadata": {},
   "source": [
    "# TITANIC DATASET 2Ô∏è‚É£ Data preparation - Preparaci√≥n de los datos\n",
    "- Se descargan los archivos CSV que son Train, Test y los datos de Test de supervivencia. \n",
    "- Se eliminan columnas innecesarias. \"Cabin\", \"PassengerId\", \"Ticket\", \"Name\"\n",
    "- Se modifica las letras de embarque por los nombres de cada puerto real. \"S\" por \"Southampton\", \"C\" por \"Cherbourg\" y \"Q\" por \"Queenstown\".\n",
    "- Se aplica One Hot Encoding a la columna Embarked dado que es nominal y no tiene un orden especifico.\n",
    "- Se aplica One Hot Encoding a la columna Sex ya que es nominal y no depende de ning√∫n orden espec√≠fico.\n",
    "- Se cre√≥ una nueva columna para obtener el tama√±o de la familia \"FamilySize\", es el total que incluye conyuges, hijos, padres y la persona.\n",
    "- Se imput√≥ la columna Age por el promedio de los datos de Train.\n",
    "- Se imput√≥ la columna Fare por el promedio de los datos de Train. Ya que en los datos de Test exist√≠a valores null.\n",
    "- Se elimina columnas no deseadas a prop√≥sito del usuario.\n",
    "- Finalmente se crean el DatasetSplit de datos que contiene los Datasets con la informaci√≥n \"X\" y \"y\" tanto para Train como para Test.\n",
    "- Se muestra la tabla de correlaci√≥n completa. Las tablas de correlaci√≥n fuerte y d√©bil con un umbral de 0.4. Si las correlaciones son mayores o iguales al umbral se muestran en la tabla de correlaci√≥n fuerte caso contrario no se muestran. Si las correlaciones son menores al umbral se muestran en la tabla de correlaci√≥n d√©bil caso contrario no se muestran. \n",
    " \n",
    "Con un umbral de 0.4 existe correlaci√≥n fuerte moderada del 26% en las columnas y el 74% no tiene correlaci√≥n fuerte. \n",
    "\n",
    "- Finalmente quedan listos los datos listos para utilizar en un entrenamiento con algoritmo supervisado y posteriormente hacer los tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADS_DIR = \"Temp\"\n",
    "TITANIC_TEST_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicTest.csv\"\n",
    "TITANIC_TEST_GENDER_SUB_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicGenderSub.csv\"\n",
    "TITANIC_TRAIN_DATA_URL = \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/raw/refs/heads/main/Datasets/TitanicTrain.csv\"\n",
    "TITANIC_TEST_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicTest.csv\")\n",
    "TITANIC_TRAIN_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicTrain.csv\")\n",
    "TITANIC_TEST_GENDER_SUB_FILENAME = os.path.join(DOWNLOADS_DIR, \"TitanicGenderSub.csv\")\n",
    "\n",
    "\n",
    "# Carga y preprocesa el dataset de Titanic, retornando el split Train/Test. \n",
    "def LoadTitanicDatasetSplit(toDrop: list[str]=[])-> DatasetSplit:\n",
    "    toDrop = [c for c in toDrop if c != \"Survived\"]\n",
    "    DownloadFile(TITANIC_TEST_DATA_URL, TITANIC_TEST_FILENAME, printInfo=False)\n",
    "    DownloadFile(TITANIC_TRAIN_DATA_URL, TITANIC_TRAIN_FILENAME, printInfo=False)\n",
    "    DownloadFile(TITANIC_TEST_GENDER_SUB_DATA_URL, TITANIC_TEST_GENDER_SUB_FILENAME, printInfo=False)\n",
    "    dfTrain = pd.read_csv(TITANIC_TRAIN_FILENAME)\n",
    "    dfTest = pd.read_csv(TITANIC_TEST_FILENAME)\n",
    "    dfTestGenderSub = pd.read_csv(TITANIC_TEST_GENDER_SUB_FILENAME)\n",
    "\n",
    "    toDiscard = [\"Cabin\", \"PassengerId\", \"Ticket\", \"Name\"]\n",
    "    dfTrain = dfTrain.drop(columns=toDiscard)\n",
    "    dfTest  = dfTest.drop(columns=toDiscard)\n",
    "\n",
    "    dtypeMap = {\n",
    "        \"Survived\": \"int64\",\n",
    "        \"Pclass\": \"int64\",\n",
    "        \"Sex\": \"string\",\n",
    "        \"Age\": \"float64\",\n",
    "        \"SibSp\": \"int64\",\n",
    "        \"Parch\": \"int64\",\n",
    "        \"Fare\": \"float64\",\n",
    "        \"Embarked\": \"string\"\n",
    "    }\n",
    "\n",
    "    dfTrain = dfTrain.astype(dtypeMap)\n",
    "    dfTest  = dfTest.astype({col: dtypeMap[col] for col in dfTest.columns})\n",
    "\n",
    "    mapEmbarked = {\n",
    "        \"S\": \"Southampton\",\n",
    "        \"C\": \"Cherbourg\",\n",
    "        \"Q\": \"Queenstown\"\n",
    "    }\n",
    "    dfTrain[\"Embarked\"] = dfTrain[\"Embarked\"].replace(mapEmbarked)\n",
    "    dfTest[\"Embarked\"]  = dfTest[\"Embarked\"].replace(mapEmbarked)\n",
    "\n",
    "    dfTrain = pd.get_dummies(dfTrain, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "    dfTest  = pd.get_dummies(dfTest, columns=[\"Embarked\"], prefix=\"Embarked\")\n",
    "\n",
    "    dfTrain = pd.get_dummies(dfTrain, columns=[\"Sex\"], prefix=\"Sex\", drop_first=False)\n",
    "    dfTest  = pd.get_dummies(dfTest, columns=[\"Sex\"], prefix=\"Sex\", drop_first=False)\n",
    "\n",
    "    dfTrain[\"FamilySize\"] = dfTrain[\"SibSp\"] + dfTrain[\"Parch\"] + 1\n",
    "    dfTest[\"FamilySize\"] = dfTest[\"SibSp\"] + dfTest[\"Parch\"] + 1\n",
    "\n",
    "    meanAge = dfTrain[\"Age\"].mean()\n",
    "    dfTrain[\"Age\"] = dfTrain[\"Age\"].fillna(meanAge)\n",
    "    dfTest[\"Age\"]  = dfTest[\"Age\"].fillna(meanAge)\n",
    "\n",
    "    meanFare = dfTrain[\"Fare\"].mean()\n",
    "    dfTrain[\"Fare\"] = dfTrain[\"Fare\"].fillna(meanAge)\n",
    "    dfTest[\"Fare\"]  = dfTest[\"Fare\"].fillna(meanAge)\n",
    "\n",
    "    NormalizeColumnNames(dfTrain)\n",
    "    NormalizeColumnNames(dfTest)\n",
    "\n",
    "    dfTrain = DropColumns(dfTrain, toDrop, inplace=True)\n",
    "    dfTest  = DropColumns(dfTest, toDrop, inplace=True)\n",
    "\n",
    "    XTrain = dfTrain.drop(columns=[\"Survived\"])\n",
    "    yTrain = dfTrain[[\"Survived\"]].copy()\n",
    "    XTest  = dfTest\n",
    "    yTest  = dfTestGenderSub[[\"Survived\"]].copy()\n",
    "    return DatasetSplit(\n",
    "        Train=Dataset(X=XTrain, y=yTrain),\n",
    "        Test=Dataset(X=XTest, y=yTest)\n",
    "    )\n",
    "\n",
    "ShowTitleBox(\"EXPLORACI√ìN INICIAL TITANIC DATASET\", color=ConsoleColor.MAGENTA, boxLineStyle= TitleBoxLineStyle.BLOCK)\n",
    "ShowTitleBox(\"CARGANDO EL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "split0 = LoadTitanicDatasetSplit()\n",
    "ShowTitleBox(\"INFO DEL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "title = \"Titanic Dataset Split\"\n",
    "ShowDatasetSplitInfo(split0, title, headQty=10)\n",
    "\n",
    "ShowTitleBox(\"MATRIZ DE CORRELACI√ìN\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "title = \"TITANIC Data original TRAIN\"\n",
    "CORR_UMBRAL = 0.4\n",
    "_=ShowDfCorrelation(split0.Train.X, title, level=CorrelationType.ALL, showTable=True, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "_=ShowDfCorrelation(split0.Train.X, title, level=CorrelationType.STRONG, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "_=ShowDfCorrelation(split0.Train.X, title, level=CorrelationType.WEAK, showTable=False, figsize=(10,8), annotate=True, umbral=CORR_UMBRAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682599e",
   "metadata": {},
   "source": [
    "# TITANIC DATASET 3Ô∏è‚É£ y 4Ô∏è‚É£ Modeling - Evaluating - Aplicaci√≥n del modelo y evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74443d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitEscaled = ScaleDatasetSplit(  LoadTitanicDatasetSplit())\n",
    "splitWithPCA = ApplyPCA( ScaleDatasetSplit(  LoadTitanicDatasetSplit()))\n",
    "splitEscaledMinMax = ScaleDatasetSplit(  LoadTitanicDatasetSplit(), scaler=CreateScaler(ScalerType.MIN_MAX))\n",
    "splitWithPCAMinMax = ApplyPCA( ScaleDatasetSplit(  LoadTitanicDatasetSplit(), scaler=CreateScaler(ScalerType.MIN_MAX)))\n",
    "allSplits = [splitEscaled, splitWithPCA, splitEscaledMinMax, splitWithPCAMinMax]\n",
    "\n",
    "EvaluateDatasetSplits(\n",
    "    splitList=allSplits,\n",
    "    targetColumn=\"Survived\",\n",
    "    includeRNA=True,\n",
    "    showConfusionMatrix=True\n",
    ")\n",
    "\n",
    "ShowTitleBox(\"GENERACI√ìN DE TABLA DE M√âTRICAS\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "dfMetrics = GenerateMetricsTable(allSplits, targetColumn=\"Survived\", includeRNA=True)\n",
    "display(dfMetrics)\n",
    "\n",
    "ShowTitleBox(\"GR√ÅFICA DE ACCURACY POR SPLIT Y MODELO\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "PlotAccuracyBySplit(dfMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a7e66",
   "metadata": {},
   "source": [
    "# üèÅ Resultados üèÅ\n",
    "\n",
    "Se tiene 4 datasets para probar:\n",
    "\n",
    "- Dataset original escalado con StandardScaler.\n",
    "- Dataset original escalado con Standard Scaler y aplicado PCA.\n",
    "- Dataset original escalado con MinMaxScaler.\n",
    "- Dataset original escalado con MinMax Scaler y aplicado PCA.\n",
    "\n",
    "\n",
    "Aplicamos cada uno de los modelos y generamos la tabla de m√©tricas. Con la tabla de m√©tricas mostramos un gr√°fico de barras con las accuracy de cada modelo por cada DatasetSplit.\n",
    "\n",
    "Las mejores opciones para predecir son KNN, LR y RNA para este dataset. RF y DT dan resultados pobres. Utilizando MinMax Scaler se tiene el mejor rendimiento tanto con Scalado como con PCA.\n",
    "\n",
    "El modelo ganador para cualquier dataset escalado o con PCA es la *RNA*. Que da un resultado en accuracy de 0.99 con escalado y 0.95 con PCA. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
