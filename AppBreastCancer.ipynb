{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e47d53a",
   "metadata": {},
   "source": [
    "<div style=\"display: table; width: 100%;\">\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 70%;\">\n",
    "    <h1>Herramientas para Data Science</h1>\n",
    "  </div>\n",
    "  <div style=\"display: table-cell; text-align: center; vertical-align: middle; width: 30%;\">\n",
    "    <img src=\"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1/blob/main/Assets/UideLogo.png?raw=true\" alt=\"logo UIDE\" style=\"width:50%;\">\n",
    "  </div>\n",
    "</div>\n",
    "<hr />\n",
    "\n",
    "### üü¶ Componente Pr√°ctico 1  \n",
    "üü° Grupo: 3      \n",
    "üü° Semana: 1      \n",
    "üü° Docente:  Ing. Iv√°n Garc√≠a S., PhD. (idgs78@hotmail.com)     \n",
    "\n",
    "### üü¶ Realizado por:   \n",
    "Estudiantes\n",
    "\n",
    "üíª Evelin Rosero Ordo√±ez   \n",
    "\n",
    "üíª Marjorie Muso Tandalla\n",
    "\n",
    "üíª Jos√© Espinoza Bone\n",
    "\n",
    "### üü¶ Objetivo y alcance del trabajo \n",
    "- Esta pr√°ctica tiene el objetivo de realizar un preprocesamiento de datos y un An√°lisis \n",
    "exploratorio de datos (estad√≠sticas y visualizaci√≥n) de las variables m√°s relevantes \n",
    "que considere para el prop√≥sito de predicci√≥n de c√°ncer de mama. Al finalizar la \n",
    "pr√°ctica, los maestrantes podr√°n manipular adecuadamente un dataset de datos \n",
    "estructurados (alfanum√©ricos). [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "\n",
    "\n",
    "### üü¶ [C√≥digo fuente original](https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1.git)\n",
    "Con [git](https://git-scm.com/) instalado. En Windows, Linux o MacOS ejecutar el comando.\n",
    "\n",
    "```\n",
    "git clone \"https://github.com/UIDE-Tareas/6-Herramientas-Data-Science-Tarea1.git\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bb6d5",
   "metadata": {},
   "source": [
    "# 0Ô∏è‚É£ Preparar entorno\n",
    "\n",
    "Funciones base para utilizar si son requeridas en el presente notebook. Adicional hay funciones utilitarias para utilizar con pandas.DataFrame y finalmente las funciones para cumplir con los objetivos del presente trabajo pr√°ctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIDADES PARA GESTI√ìN DE DEPENDENCIAS E INFORMACI√ìN DEL ENTORNO\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import zipfile\n",
    "from typing import Optional\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "from typing import cast\n",
    "from typing import Tuple\n",
    "from types import SimpleNamespace\n",
    "from typing import Any\n",
    "from typing import Protocol\n",
    "from typing import Literal\n",
    "from typing import Sequence\n",
    "\n",
    "# Libs a instalar\n",
    "LIBS = [\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"requests\",\n",
    "    \"wcwidth\",\n",
    "]\n",
    "\n",
    "class ConsoleColor(Enum):\n",
    "    RED = \"\\033[91m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    BLUE = \"\\033[94m\"\n",
    "    MAGENTA = \"\\033[95m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    WHITE = \"\\033[97m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def PrintColor(message: str, color: ConsoleColor) -> str:\n",
    "    RESET = ConsoleColor.RESET.value\n",
    "    return f\"{color.value}{message}{RESET}\"\n",
    "\n",
    "\n",
    "def ShowMessage(\n",
    "    message: str, title: str, icon: str, color: ConsoleColor, end: str = \"\\n\"\n",
    "):\n",
    "    colored_title = PrintColor(icon + f\"  \" + title.upper() + \":\", color)\n",
    "    print(f\"{colored_title} {message}\", end=end)\n",
    "\n",
    "\n",
    "def ShowInfoMessage(\n",
    "    message: str, title: str = \"Info\", icon: str = \"‚ÑπÔ∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.CYAN, end)\n",
    "\n",
    "\n",
    "def ShowSuccessMessage(\n",
    "    message: str, title: str = \"Success\", icon: str = \"‚úÖ\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.GREEN, end)\n",
    "\n",
    "\n",
    "def ShowErrorMessage(\n",
    "    message: str, title: str = \"Error\", icon: str = \"‚ùå\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.RED, end)\n",
    "\n",
    "\n",
    "def ShowWarningMessage(\n",
    "    message: str, title: str = \"Warning\", icon: str = \"‚ö†Ô∏è\", end: str = \"\\n\"\n",
    "):\n",
    "    ShowMessage(message, title, icon, ConsoleColor.YELLOW, end)\n",
    "\n",
    "\n",
    "# Funcion para ejecutar comandos\n",
    "def RunCommand(\n",
    "    commandList: list[str], printCommand: bool = True, printError: bool = True\n",
    ") -> subprocess.CompletedProcess[str]:\n",
    "    print(\"‚è≥\", \" \".join(commandList))\n",
    "\n",
    "    if printCommand:\n",
    "        proc = subprocess.Popen(\n",
    "            commandList,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            bufsize=1,\n",
    "            universal_newlines=True,\n",
    "        )\n",
    "\n",
    "        out_lines: list[str] = []\n",
    "        assert proc.stdout is not None\n",
    "        for line in proc.stdout:\n",
    "            print(line, end=\"\")\n",
    "            out_lines.append(line)\n",
    "\n",
    "        proc.wait()\n",
    "        err_text = \"\"\n",
    "        if proc.stderr is not None:\n",
    "            err_text = proc.stderr.read() or \"\"\n",
    "\n",
    "        if proc.returncode != 0 and printError and err_text:\n",
    "            ShowErrorMessage(err_text, \"\", end=\"\")\n",
    "            # print(err_text, end=\"\")\n",
    "\n",
    "        return subprocess.CompletedProcess(\n",
    "            args=commandList,\n",
    "            returncode=proc.returncode,\n",
    "            stdout=\"\".join(out_lines),\n",
    "            stderr=err_text,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        result = subprocess.run(\n",
    "            commandList, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "        if result.returncode != 0 and printError and result.stderr:\n",
    "            ShowErrorMessage(result.stderr, \"\", end=\"\")\n",
    "            # print(result.stderr, end=\"\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# Funci√≥n para instalar las dependencias\n",
    "def InstallDeps(libs: Optional[list[str]] = None):\n",
    "    print(\"‚ÑπÔ∏è Installing deps.\")\n",
    "    printCommand = False\n",
    "    printError = True\n",
    "    RunCommand(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"],\n",
    "        printCommand=printCommand,\n",
    "        printError=printError,\n",
    "    )\n",
    "    if libs is None or libs.count == 0:\n",
    "        print(\"No hay elementos a instalar.\")\n",
    "    else:\n",
    "        RunCommand(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", *libs],\n",
    "            printCommand=printCommand,\n",
    "            printError=printError,\n",
    "        )\n",
    "        print(\"Deps installed.\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar info el ambiente de ejecuci√≥n\n",
    "def ShowEnvironmentInfo():\n",
    "    print(\"‚ÑπÔ∏è  Environment Info:\")\n",
    "    print(\"Python Version:\", sys.version)\n",
    "    print(\"Platform:\", sys.platform)\n",
    "    print(\"Executable Path:\", sys.executable)\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "    print(\"VIRTUAL_ENV:\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "    print(\"sys.prefix:\", sys.prefix)\n",
    "    print(\"sys.base_prefix:\", sys.base_prefix)\n",
    "    print()\n",
    "\n",
    "\n",
    "InstallDeps(LIBS)\n",
    "ShowEnvironmentInfo()\n",
    "import requests\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BoxStyle:\n",
    "    TL: str\n",
    "    TR: str\n",
    "    BL: str\n",
    "    BR: str\n",
    "    H: str\n",
    "    V: str\n",
    "\n",
    "class TitleBoxLineStyle(Enum):\n",
    "    SIMPLE = BoxStyle(\"‚îå\", \"‚îê\", \"‚îî\", \"‚îò\", \"‚îÄ\", \"‚îÇ\")\n",
    "    DOUBLE = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ïê\", \"‚ïë\")\n",
    "    ROUNDED = BoxStyle(\"‚ï≠\", \"‚ïÆ\", \"‚ï∞\", \"‚ïØ\", \"‚îÄ\", \"‚îÇ\")\n",
    "    HEAVY = BoxStyle(\"‚îè\", \"‚îì\", \"‚îó\", \"‚îõ\", \"‚îÅ\", \"‚îÉ\")\n",
    "    ASCII = BoxStyle(\"+\", \"+\", \"+\", \"+\", \"-\", \"|\")\n",
    "    DOUBLE_BOLD = BoxStyle(\"‚ïî\", \"‚ïó\", \"‚ïö\", \"‚ïù\", \"‚ï¨\", \"‚ïë\")\n",
    "    BLOCK = BoxStyle(\"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\", \"‚ñà\")\n",
    "    HEAVY_CROSS = BoxStyle(\"‚ïí\", \"‚ïï\", \"‚ïò\", \"‚ïõ\", \"‚ï™\", \"‚îÉ\")\n",
    "    METAL = BoxStyle(\"‚ïû\", \"‚ï°\", \"‚ïò\", \"‚ïõ\", \"‚ïê\", \"‚ïë\")\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar un t√≠tulo con recuadro\n",
    "def ShowTitleBox(\n",
    "    text: str,\n",
    "    max_len: int = 100,\n",
    "    boxLineStyle: TitleBoxLineStyle = TitleBoxLineStyle.SIMPLE,\n",
    "    color: ConsoleColor = ConsoleColor.CYAN,\n",
    "):\n",
    "    try:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            from wcwidth import wcswidth as _w\n",
    "\n",
    "            n = _w(s)\n",
    "            return n if n >= 0 else len(s)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        def vislen(s: str) -> int:\n",
    "            return len(s)\n",
    "\n",
    "    pad = 1\n",
    "    tlen = vislen(text)\n",
    "    inner = max(max_len, tlen)\n",
    "    left = (inner - tlen) // 2\n",
    "    right = inner - tlen - left\n",
    "\n",
    "    top = f\"{boxLineStyle.value.TL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.TR}\"\n",
    "    mid = f\"{boxLineStyle.value.V}{' ' * pad}{' ' * left}{text}{' ' * right}{' ' * pad}{boxLineStyle.value.V}\"\n",
    "    bot = f\"{boxLineStyle.value.BL}{boxLineStyle.value.H * (inner + 2 * pad)}{boxLineStyle.value.BR}\"\n",
    "    print(PrintColor(\"\\n\".join([top, mid, bot]), color))\n",
    "\n",
    "\n",
    "# Funci√≥n para descargar un archivo\n",
    "def DownloadFile(uri: str, filename: str, overwrite: bool = False, timeout: int = 20, printInfo: bool = True):\n",
    "    dest = Path(filename).resolve()\n",
    "    if dest.exists() and dest.is_file() and dest.stat().st_size > 0 and not overwrite:\n",
    "        if printInfo:\n",
    "            print(\n",
    "                f'‚úÖ Ya existe: \"{dest}\". No se descarga (use overwrite=True para forzar).'\n",
    "            )\n",
    "        return\n",
    "    if dest.parent and not dest.parent.exists():\n",
    "        dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if printInfo:\n",
    "        print(f'‚ÑπÔ∏è Descargando \"{uri}\" ‚Üí \"{dest}\"')\n",
    "    try:\n",
    "        with requests.get(uri, stream=True, timeout=timeout) as resp:\n",
    "            resp.raise_for_status()\n",
    "            tmp = dest.with_suffix(dest.suffix + \".part\")\n",
    "            with open(tmp, \"wb\") as f:\n",
    "                for chunk in resp.iter_content(chunk_size=1024 * 64):\n",
    "                    if chunk:  # filtra keep-alive chunks\n",
    "                        f.write(chunk)\n",
    "            tmp.replace(dest)\n",
    "        if printInfo: \n",
    "            print(f'‚úÖ Archivo \"{dest}\" descargado exitosamente.')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error al descargar: {e}\")\n",
    "\n",
    "\n",
    "# Funci√≥n para descomprimir un archivo zip\n",
    "def UnzipFile(filename: str, outputDir: str):\n",
    "    print(f'‚ÑπÔ∏è Descomprimiendo \"{filename}\" en \"{outputDir}\"')\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(outputDir)\n",
    "        print(f\"Descomprimido en: {os.path.abspath(outputDir)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILIDADES PARA AN√ÅLISIS Y MANIPULACI√ìN DE DATAFRAMES\n",
    "\n",
    "# Importar libraries\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurar opciones de Pandas\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "pandas.set_option(\"display.max_rows\", None)\n",
    "pandas.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la informaci√≥n del DataFrame.\n",
    "def ShowDfInfo(df: pandas.DataFrame, title):\n",
    "    display(f\"‚ÑπÔ∏è INFO {title} ‚ÑπÔ∏è\")\n",
    "    df.info()\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n primeras filas del DataFrame.\n",
    "def ShowDfHead(df: pandas.DataFrame, title: str, headQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: Primeros {headQty} elementos.\")\n",
    "    display(df.head(headQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar las n √∫ltimas filas del DataFrame.\n",
    "def ShowDfTail(df: pandas.DataFrame, title: str, tailQty=10):\n",
    "    display(f\"‚ÑπÔ∏è {title}: √öltimos {tailQty} elementos.\")\n",
    "    display(df.tail(tailQty))\n",
    "    display()\n",
    "\n",
    "\n",
    "# Mostrar el tama√±o del DataFrame\n",
    "def ShowDfShape(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è {title} - Tama√±o de los datos\")\n",
    "    display(f\"{df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "    display()\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la estad√≠stica descriptiva de todas las columnas del DataFrame, por tipo de dato.\n",
    "def ShowDfStats(df: pandas.DataFrame, title: str = \"\"):\n",
    "    display(f\"‚ÑπÔ∏è Estad√≠stica descriptiva - {title}\")\n",
    "    numeric_cols = df.select_dtypes(include=\"number\")\n",
    "    if not numeric_cols.empty:\n",
    "        display(\"    üî¢ Columnas num√©ricas\".upper())\n",
    "        numeric_desc = (\n",
    "            numeric_cols.describe().round(2).T\n",
    "        )  # Transpuesta para a√±adir columna\n",
    "        numeric_desc[\"var\"] = numeric_cols.var(numeric_only=True).round(2)\n",
    "        display(numeric_desc.T)\n",
    "    non_numeric_cols = df.select_dtypes(\n",
    "        include=[\"boolean\", \"string\", \"category\", \"object\"]\n",
    "    )\n",
    "    if not non_numeric_cols.empty:\n",
    "        display(\"    üî° Columnas no num√©ricas\".upper())\n",
    "        non_numeric_desc = non_numeric_cols.describe()\n",
    "        display(non_numeric_desc)\n",
    "    datetime_cols = df.select_dtypes(include=[\"datetime\", \"datetimetz\"])\n",
    "    if not datetime_cols.empty:\n",
    "        display(\"    üìÖ Columnas fechas\".upper())\n",
    "        datetime_desc = datetime_cols.describe()\n",
    "        display(datetime_desc)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar una visi√≥n general completa del DataFrame\n",
    "def ShowFullDfOverview(df, title, headQty=5, tailQty=5):\n",
    "    ShowDfInfo(df, title)\n",
    "    ShowDfStats(df, title)\n",
    "    ShowDfShape(df, title)\n",
    "    ShowDfHead(df, title, headQty=headQty)\n",
    "    ShowDfTail(df, title, tailQty=tailQty)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar los valores nulos o NaN de cada columna en un DataFrame\n",
    "def ShowDfNanValues(df: pandas.DataFrame, title: str):\n",
    "    display(f\"‚ÑπÔ∏è Contador de valores Nulos - {title}\")\n",
    "    nulls_count = df.isnull().sum()\n",
    "    nulls_df = nulls_count.reset_index()\n",
    "    nulls_df.columns = [\"Columna\", \"Cantidad_Nulos\"]\n",
    "    display(nulls_df)\n",
    "    display()\n",
    "\n",
    "\n",
    "# Tipos de correlaci√≥n\n",
    "class CorrelationType(Enum):\n",
    "    ALL = \"all\"\n",
    "    STRONG = \"strong\"\n",
    "    WEAK = \"weak\"\n",
    "\n",
    "\n",
    "# Muestra las correlaciones completas, d√©biles y fuertes.\n",
    "def ShowDfCorrelation(\n",
    "    df: pandas.DataFrame,\n",
    "    title: str,\n",
    "    fig: Optional[Figure] = None,\n",
    "    ax: Optional[Axes] = None,\n",
    "    level: CorrelationType = CorrelationType.ALL,\n",
    "    umbral: float = 0.6,\n",
    "    showTable: bool = False,\n",
    "    figsize: tuple = (8, 6),\n",
    "    annotate: bool = True,\n",
    "):\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    display(f\"‚ÑπÔ∏è {(title).upper()} - Matriz de Correlaci√≥n, Type: {level.name}\")\n",
    "\n",
    "    corr = df.select_dtypes(include=[\"number\"]).corr().copy()\n",
    "\n",
    "    if level == CorrelationType.STRONG:\n",
    "        corr = corr.where(np.abs(corr) >= umbral)\n",
    "    elif level == CorrelationType.WEAK:\n",
    "        corr = corr.where(np.abs(corr) < umbral)\n",
    "        np.fill_diagonal(corr.values, 1)\n",
    "    elif level != CorrelationType.ALL:\n",
    "        raise ValueError(f\"Invalid level: {level}\")\n",
    "\n",
    "    cax = ax.matshow(corr, vmin=-1, vmax=1)\n",
    "\n",
    "    cols = corr.columns\n",
    "    ax.set_xticks(range(len(cols)))\n",
    "    ax.set_yticks(range(len(cols)))\n",
    "    ax.set_xticklabels(cols, rotation=90, ha=\"left\")\n",
    "    ax.set_yticklabels(cols)\n",
    "\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    if annotate:\n",
    "        for (i, j), value in np.ndenumerate(corr.values):\n",
    "            if not np.isnan(value):\n",
    "                ax.text(j, i, f\"{value:+.2f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    if level == CorrelationType.ALL:\n",
    "        titulo = \"Matriz de correlaci√≥n completa\"\n",
    "    else:\n",
    "        titulo = f\"Matriz de correlaci√≥n ({level.name}, umbral={umbral})\"\n",
    "\n",
    "    total_elementos = corr.size\n",
    "    total_nodiagonal = corr.size - corr.shape[0]\n",
    "    total_nan = corr.isna().sum().sum()\n",
    "    total_validos = total_elementos - total_nan - corr.shape[0]\n",
    "\n",
    "    titulo = (\n",
    "        f\"{titulo}, Total Matriz: {total_nodiagonal}, \"\n",
    "        f\"Total v√°lidos: {total_validos} ({((total_validos * 100) / total_nodiagonal):.2f}%)\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(titulo, pad=20)\n",
    "    ax.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if showTable:\n",
    "        display(corr)\n",
    "    fig.show()\n",
    "    return fig, corr\n",
    "\n",
    "\n",
    "def NormalizeColumnNames(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    df.columns = [\n",
    "        col.strip().title().replace(\" \", \"\").replace(\"_\", \"\") for col in df.columns\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def DropColumns(\n",
    "    df: pandas.DataFrame, toDrop: list[str], inplace: bool = False\n",
    ") -> pandas.DataFrame:\n",
    "    if not toDrop:\n",
    "        return df\n",
    "    if inplace:\n",
    "        df.drop(columns=df.columns.intersection(toDrop), inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        return df.drop(columns=df.columns.intersection(toDrop))\n",
    "\n",
    "\n",
    "# Para almacenar los datos del dataset\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    X: pandas.DataFrame\n",
    "    y: pandas.DataFrame\n",
    "\n",
    "\n",
    "# Para almacenar los datos de split del dataset.\n",
    "@dataclass\n",
    "class DatasetSplit:\n",
    "    Train: Dataset\n",
    "    Test: Dataset\n",
    "\n",
    "\n",
    "# Muestra el head de cada componente del split.\n",
    "def ShowDatasetSplitHead(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    ShowDfHead(split.Train.X, f\"{title} - X Train\", headQty)\n",
    "    ShowDfHead(split.Train.y, f\"{title} - y Train\", headQty)\n",
    "    ShowDfHead(split.Test.X, f\"{title} - X Test\", headQty)\n",
    "    ShowDfHead(split.Test.y, f\"{title} - y Test\", headQty)\n",
    "\n",
    "\n",
    "# Muestra la informaci√≥n del Dataset\n",
    "def ShowDatasetInfo(data: Dataset, title):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - Caracteristicas - X\"\n",
    "    ShowDfInfo(data.X, title)\n",
    "    ShowDfShape(data.X, title)\n",
    "    ShowDfStats(data.X, title)\n",
    "    ShowDfNanValues(data.X, title)\n",
    "    ShowDfHead(data.X, title)\n",
    "    ShowDfTail(data.X, title)\n",
    "    title = f\"{tAux} - Caracter√≠sticas - y\"\n",
    "    ShowDfInfo(data.y, title)\n",
    "    ShowDfShape(data.y, title)\n",
    "    ShowDfStats(data.y, title)\n",
    "    ShowDfNanValues(data.y, title)\n",
    "    ShowDfHead(data.y, title)\n",
    "    ShowDfTail(data.y, title)\n",
    "\n",
    "\n",
    "# Muestra la informaci√≥n del Dataset Split\n",
    "def ShowDatasetSplitInfo(split: DatasetSplit, title: str, headQty: int = 5):\n",
    "    tAux = title\n",
    "    title = f\"{tAux} - TRAIN\"\n",
    "    ShowDatasetInfo(split.Train, title)\n",
    "    title = f\"{tAux} - TEST\"\n",
    "    ShowDatasetInfo(split.Test, title)\n",
    "\n",
    "\n",
    "# Realiza el split del Dataset, en Train y test utilizando el ratio.\n",
    "def SplitDataset(\n",
    "    data: Dataset, trainRatio: float = 0.8, randomState: int = 42\n",
    ") -> DatasetSplit:\n",
    "    y_strat = data.y.iloc[:, 0]\n",
    "    XTrain, XTest, yTrain, yTest = train_test_split(\n",
    "        data.X,\n",
    "        data.y,\n",
    "        train_size=trainRatio,\n",
    "        random_state=randomState,\n",
    "        stratify=y_strat,\n",
    "    )\n",
    "    return DatasetSplit(\n",
    "        Train=Dataset(X=XTrain.reset_index(drop=True), y=yTrain.reset_index(drop=True)),\n",
    "        Test=Dataset(X=XTest.reset_index(drop=True), y=yTest.reset_index(drop=True)),\n",
    "    )\n",
    "\n",
    "\n",
    "# Contrato para los escaladores\n",
    "class ScalerProtocol(Protocol):\n",
    "    def fit(self, X, y: Any = None) -> Any: ...\n",
    "    def transform(self, X) -> Any: ...\n",
    "    def fit_transform(self, X, y: Any = None) -> Any: ...\n",
    "\n",
    "\n",
    "# Para almacenar los datos del dataset aplicado el escalador.\n",
    "@dataclass\n",
    "class ScaledDatasetSplit(DatasetSplit):\n",
    "    Scaler: ScalerProtocol\n",
    "\n",
    "# Enum para los tipos de escaladores soportados\n",
    "class ScalerType(Enum):\n",
    "    STANDARD = \"Standard\"\n",
    "    MIN_MAX = \"minmax\"\n",
    "    ROBUST = \"robust\"\n",
    "    MAX_ABS = \"maxabs\"\n",
    "    NORMALIZER = \"normalizer\"\n",
    "    QUANTILE = \"quantile\"\n",
    "    POWER = \"power\"\n",
    "    FUNCTION = \"function\"\n",
    "\n",
    "\n",
    "# Crea una instancia de scaler seg√∫n el Enum ScalerType.\n",
    "def CreateScaler(scalerType: ScalerType, **kwargs) -> ScalerProtocol:\n",
    "    if scalerType == ScalerType.STANDARD:\n",
    "        return StandardScaler(**kwargs)\n",
    "    if scalerType == ScalerType.MIN_MAX:\n",
    "        return MinMaxScaler(**kwargs)\n",
    "    if scalerType == ScalerType.ROBUST:\n",
    "        return RobustScaler(**kwargs)\n",
    "    if scalerType == ScalerType.MAX_ABS:\n",
    "        return MaxAbsScaler(**kwargs)\n",
    "    if scalerType == ScalerType.NORMALIZER:\n",
    "        return Normalizer(**kwargs)\n",
    "    if scalerType == ScalerType.QUANTILE:\n",
    "        return QuantileTransformer(**kwargs)\n",
    "    if scalerType == ScalerType.POWER:\n",
    "        return PowerTransformer(**kwargs)\n",
    "    if scalerType == ScalerType.FUNCTION:\n",
    "        return FunctionTransformer(**kwargs)\n",
    "    raise ValueError(f\"ScalerType no soportado: {scalerType}\")\n",
    "\n",
    "def DetectScaler(scaler: ScalerProtocol) -> ScalerType:\n",
    "    if isinstance(scaler, StandardScaler):\n",
    "        return ScalerType.STANDARD\n",
    "    if isinstance(scaler, MinMaxScaler):\n",
    "        return ScalerType.MIN_MAX\n",
    "    if isinstance(scaler, RobustScaler):\n",
    "        return ScalerType.ROBUST\n",
    "    if isinstance(scaler, MaxAbsScaler):\n",
    "        return ScalerType.MAX_ABS\n",
    "    if isinstance(scaler, Normalizer):\n",
    "        return ScalerType.NORMALIZER\n",
    "    if isinstance(scaler, QuantileTransformer):\n",
    "        return ScalerType.QUANTILE\n",
    "    if isinstance(scaler, PowerTransformer):\n",
    "        return ScalerType.POWER\n",
    "    if isinstance(scaler, FunctionTransformer):\n",
    "        return ScalerType.FUNCTION\n",
    "    raise ValueError(f\"No se reconoce el tipo de scaler: {type(scaler)}\")\n",
    "\n",
    "# Escala el split usando el escalador proporcionado y retorna el split escalado.\n",
    "def ScaleDatasetSplit(\n",
    "    split: DatasetSplit, scaler: ScalerProtocol = StandardScaler()\n",
    ") -> ScaledDatasetSplit:\n",
    "    XTrainScaledValues = scaler.fit_transform(split.Train.X)\n",
    "    XTestScaledValues = scaler.transform(split.Test.X)\n",
    "\n",
    "    XTrainScaled = pandas.DataFrame(\n",
    "        XTrainScaledValues, columns=split.Train.X.columns, index=split.Train.X.index\n",
    "    )\n",
    "\n",
    "    XTestScaled = pandas.DataFrame(\n",
    "        XTestScaledValues, columns=split.Test.X.columns, index=split.Test.X.index\n",
    "    )\n",
    "\n",
    "    TrainScaledDataset = Dataset(X=XTrainScaled, y=split.Train.y.copy())\n",
    "    TestScaledDataset = Dataset(X=XTestScaled, y=split.Test.y.copy())\n",
    "\n",
    "    return ScaledDatasetSplit(\n",
    "        Train=TrainScaledDataset, Test=TestScaledDataset, Scaler=scaler\n",
    "    )\n",
    "\n",
    "# Para almacenar los datos del dataset aplicado PCA.\n",
    "@dataclass\n",
    "class PcaDatasetSplit(DatasetSplit):\n",
    "    Pca: PCA\n",
    "    Scaler: ScalerProtocol | None = None \n",
    "\n",
    "# Aplica PCA al split escalado y retorna el split con PCA aplicado.\n",
    "def ApplyPCA(\n",
    "    split: ScaledDatasetSplit,\n",
    "    explainedVarianceRatioSum: float = 0.95,\n",
    "    randomState: int = 42\n",
    ") -> PcaDatasetSplit:\n",
    "\n",
    "    def GetPCNames(n: int) -> list[str]:\n",
    "        return [f\"PC{i}\" for i in range(1, n + 1)]\n",
    "\n",
    "    pca = PCA(n_components=explainedVarianceRatioSum, random_state=randomState)\n",
    "\n",
    "    XTrainPCA = pca.fit_transform(split.Train.X)\n",
    "    XTestPCA = pca.transform(split.Test.X)\n",
    "\n",
    "    XTrainPcaDf = pandas.DataFrame(\n",
    "        XTrainPCA, index=split.Train.X.index, columns=GetPCNames(XTrainPCA.shape[1])\n",
    "    )\n",
    "\n",
    "    XTestPcaDf = pandas.DataFrame(\n",
    "        XTestPCA, index=split.Test.X.index, columns=GetPCNames(XTestPCA.shape[1])\n",
    "    )\n",
    "\n",
    "    return PcaDatasetSplit(\n",
    "        Train=Dataset(X=XTrainPcaDf, y=split.Train.y.copy()),\n",
    "        Test=Dataset(X=XTestPcaDf, y=split.Test.y.copy()),\n",
    "        Pca=pca,\n",
    "        Scaler=split.Scaler\n",
    "    )\n",
    "\n",
    "\n",
    "# Para almacenar los resultados de la regresi√≥n log√≠stica\n",
    "@dataclass\n",
    "class LogisticRegressionResult:\n",
    "    Model: LogisticRegression\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Iters: list[int] | np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "\n",
    "# Aplica regresi√≥n log√≠stica al split escalado y retorna el resultado.\n",
    "def ApplyLogisticRegression(\n",
    "    split: ScaledDatasetSplit,\n",
    "    targetColumn: str,\n",
    "    randomState: int = 42,\n",
    "    maxIter: int = 200,\n",
    "    C: float = 1.0,\n",
    "    penalty: Literal['l1', 'l2', 'elasticnet'] | None = \"l2\",\n",
    "    solver: Literal['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'] = \"lbfgs\"\n",
    ") -> LogisticRegressionResult:\n",
    "    \n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=maxIter,\n",
    "        random_state=randomState,\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPredTrain = model.predict(XTrain)\n",
    "    yPredTest = model.predict(XTest)\n",
    "\n",
    "    yProbaTrain = model.predict_proba(XTrain)\n",
    "    yProbaTest = model.predict_proba(XTest)\n",
    "\n",
    "    dfProbaTest = pandas.DataFrame(\n",
    "        yProbaTest,\n",
    "        index=XTest.index,\n",
    "        columns=[f\"Class-{cls}-Prob\" for cls in model.classes_]\n",
    "    )\n",
    "\n",
    "    dfPredTest = pandas.DataFrame(\n",
    "        {\n",
    "            \"yReal\": yTest.values,\n",
    "            \"yPred\": yPredTest\n",
    "        },\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPredTest = pandas.concat([dfPredTest, dfProbaTest], axis=1)\n",
    "\n",
    "    acc = accuracy_score(yTest, yPredTest)\n",
    "    prec = precision_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(yTest, yPredTest, average=\"weighted\", zero_division=0)\n",
    "    cm = confusion_matrix(yTest, yPredTest)\n",
    "    report = classification_report(yTest, yPredTest)\n",
    "\n",
    "    return LogisticRegressionResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPredTest,\n",
    "        Accuracy=float(acc),\n",
    "        ConfusionMatrix=cm,\n",
    "        Precision=float(prec),\n",
    "        Recall=float(rec),\n",
    "        F1=float(f1),\n",
    "        Iters=model.n_iter_,\n",
    "        Report=str(report),\n",
    "        Target=targetColumn\n",
    "    )\n",
    "\n",
    "# Para almacenar los resultados de KNN\n",
    "@dataclass\n",
    "class KnnResult:\n",
    "    Model: KNeighborsClassifier\n",
    "    Predictions: pandas.DataFrame\n",
    "    Accuracy: float\n",
    "    Precision: float\n",
    "    Recall: float\n",
    "    F1: float\n",
    "    ConfusionMatrix: np.ndarray\n",
    "    Report: str\n",
    "    Target: str\n",
    "    K: int\n",
    "\n",
    "def GetBestKForKNN(\n",
    "    split: ScaledDatasetSplit,\n",
    "    targetColumn: str,\n",
    "    kMax: int = 30\n",
    ") -> int:\n",
    "    \n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    bestK = 1\n",
    "    bestScore = -1.0\n",
    "\n",
    "    for k in range(1, kMax + 1):\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(XTrain, yTrain)\n",
    "\n",
    "        yPred = model.predict(XTest)\n",
    "        acc = accuracy_score(yTest, yPred)\n",
    "\n",
    "        if acc > bestScore:\n",
    "            bestScore = acc\n",
    "            bestK = k\n",
    "    return bestK\n",
    "\n",
    "def ApplyKNN(\n",
    "    split: ScaledDatasetSplit,\n",
    "    targetColumn: str,\n",
    "    weights: Literal[\"uniform\", \"distance\"] = \"uniform\",\n",
    "    metric: Literal[\n",
    "        \"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"\n",
    "    ] = \"minkowski\"\n",
    ") -> KnnResult:\n",
    "    K = GetBestKForKNN(split, targetColumn)\n",
    "    XTrain = split.Train.X\n",
    "    yTrain = split.Train.y[targetColumn]\n",
    "    XTest = split.Test.X\n",
    "    yTest = split.Test.y[targetColumn]\n",
    "\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=K,\n",
    "        weights=weights,\n",
    "        metric=metric\n",
    "    )\n",
    "\n",
    "    model.fit(XTrain, yTrain)\n",
    "\n",
    "    yPred = model.predict(XTest)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        yProba = model.predict_proba(XTest)\n",
    "        dfProba = pandas.DataFrame(\n",
    "            yProba,\n",
    "            index=XTest.index,\n",
    "            columns=[f\"Class-{cls}-Prob\" for cls in model.classes_],\n",
    "        )\n",
    "    else:\n",
    "        dfProba = pandas.DataFrame(index=XTest.index)\n",
    "\n",
    "    dfPred = pandas.DataFrame(\n",
    "        {\n",
    "            \"yReal\": yTest.values,\n",
    "            \"yPred\": yPred,\n",
    "        },\n",
    "        index=XTest.index\n",
    "    )\n",
    "\n",
    "    dfPred = pandas.concat([dfPred, dfProba], axis=1)\n",
    "\n",
    "    acc = accuracy_score(yTest, yPred)\n",
    "    prec = precision_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(yTest, yPred, average=\"weighted\", zero_division=0)\n",
    "    cm = confusion_matrix(yTest, yPred)\n",
    "    report = classification_report(yTest, yPred)\n",
    "\n",
    "    return KnnResult(\n",
    "        Model=model,\n",
    "        Predictions=dfPred,\n",
    "        Accuracy=float(acc),\n",
    "        Precision=float(prec),\n",
    "        Recall=float(rec),\n",
    "        F1=float(f1),\n",
    "        ConfusionMatrix=cm,\n",
    "        Report=str(report),\n",
    "        Target=targetColumn,\n",
    "        K=K\n",
    "    )\n",
    "\n",
    "\n",
    "def PlotConfusionMatrix(\n",
    "    cm,\n",
    "    classNames: Sequence[str] | None = None,\n",
    "    title: str = \"Confusion Matrix\"\n",
    "):\n",
    "    # Si classNames es None ‚Üí usar \"auto\"\n",
    "    xticks = classNames if classNames is not None else \"auto\"\n",
    "    yticks = classNames if classNames is not None else \"auto\"\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=xticks,\n",
    "        yticklabels=yticks\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Utilidades para detecci√≥n de tipos de split\n",
    "@dataclass(frozen=True)\n",
    "class SplitTypeInfo:\n",
    "    IsPCA: bool\n",
    "    IsScaled: bool\n",
    "    IsRaw: bool\n",
    "\n",
    "# Detecta el tipo de split (PCA, Escalado, Crudo)\n",
    "def DetectSplitType(split) -> SplitTypeInfo:\n",
    "    isPca = isinstance(split, PcaDatasetSplit)\n",
    "    isScaled = isinstance(split, ScaledDatasetSplit)\n",
    "    isRaw = not isPca and not isScaled\n",
    "\n",
    "    return SplitTypeInfo(\n",
    "        IsPCA=isPca,\n",
    "        IsScaled=isScaled,\n",
    "        IsRaw=isRaw\n",
    "    )\n",
    "\n",
    "def GenerateMetricsTable(splitList: list[DatasetSplit], targetColumn:str) -> pandas.DataFrame:\n",
    "    results = []\n",
    "\n",
    "    for idx, split in enumerate(splitList, start=1):\n",
    "\n",
    "        # Detectar tipo de split\n",
    "        splitInfo = DetectSplitType(split)\n",
    "\n",
    "        # Nombre del scaler o None\n",
    "        scalerName = (\n",
    "            DetectScaler(split.Scaler).value\n",
    "            if (splitInfo.IsScaled and hasattr(split, \"Scaler\") and split.Scaler is not None)\n",
    "            else \"None\"\n",
    "        )\n",
    "\n",
    "        # Tipo del split\n",
    "        if splitInfo.IsPCA:\n",
    "            splitType = \"PCA\"\n",
    "        elif splitInfo.IsScaled:\n",
    "            splitType = \"SCALED\"\n",
    "        else:\n",
    "            splitType = \"RAW\"\n",
    "\n",
    "        # Ejecutar modelos\n",
    "        resultLR = ApplyLogisticRegression(split, targetColumn=targetColumn)\n",
    "        resultKNN = ApplyKNN(split, targetColumn=targetColumn)\n",
    "\n",
    "        # Guardar info en lista\n",
    "        results.append({\n",
    "            \"Index\": idx,\n",
    "            \"Type\": splitType,\n",
    "            \"Scaler\": scalerName,\n",
    "            # M√©tricas Logistic Regression\n",
    "            \"LR_Accuracy\": resultLR.Accuracy,\n",
    "            \"LR_Precision\": resultLR.Precision,\n",
    "            \"LR_Recall\": resultLR.Recall,\n",
    "            \"LR_F1\": resultLR.F1,\n",
    "            # M√©tricas KNN\n",
    "            \"KNN_BestK\": resultKNN.K,\n",
    "            \"KNN_Accuracy\": resultKNN.Accuracy,\n",
    "            \"KNN_Precision\": resultKNN.Precision,\n",
    "            \"KNN_Recall\": resultKNN.Recall,\n",
    "            \"KNN_F1\": resultKNN.F1,\n",
    "        })\n",
    "\n",
    "    # Convertir a DataFrame final\n",
    "    df = pandas.DataFrame(results)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def EvaluateSplits(splitList: list[DatasetSplit], targetColumn: str):\n",
    "\n",
    "    i = 0\n",
    "    for split in splitList:\n",
    "        splitInfo = DetectSplitType(split)\n",
    "        i += 1\n",
    "\n",
    "        title = (\n",
    "            f\"{i}.- Data - Scaled = {splitInfo.IsScaled} - PCA = {splitInfo.IsPCA} \"\n",
    "            f\"- Features({split.Train.X.columns.size}): \"\n",
    "            + \", \".join(split.Train.X.columns.tolist())\n",
    "            + \", Scaler: \"\n",
    "            + (\n",
    "                DetectScaler(split.Scaler).value\n",
    "                if (splitInfo.IsScaled and hasattr(split, 'Scaler') and split.Scaler is not None)\n",
    "                else \"None\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ShowTitleBox(title, color=ConsoleColor.CYAN, boxLineStyle=TitleBoxLineStyle.SIMPLE)\n",
    "        ShowDfInfo(split.Train.X, f\"{title}\")\n",
    "        ShowDfHead(split.Train.X, f\"{title}\", headQty=5)\n",
    "\n",
    "        result1 = ApplyLogisticRegression(split, targetColumn=targetColumn)\n",
    "        result2 = ApplyKNN(split, targetColumn=targetColumn)\n",
    "\n",
    "        ShowTitleBox(\"RESULTADOS REGRESI√ìN LOG√çSTICA\",\n",
    "                     color=ConsoleColor.YELLOW,\n",
    "                     boxLineStyle=TitleBoxLineStyle.HEAVY)\n",
    "\n",
    "        print(f\"Accuracy: {result1.Accuracy:.4f}\")\n",
    "        print(f\"Precision: {result1.Precision:.4f}\")\n",
    "        print(f\"Recall: {result1.Recall:.4f}\")\n",
    "        print(f\"F1 Score: {result1.F1:.4f}\")\n",
    "\n",
    "        print(\"Confusion Matrix:\")\n",
    "        PlotConfusionMatrix(\n",
    "            result1.ConfusionMatrix,\n",
    "            classNames=result1.Model.classes_,\n",
    "            title=\"Logistic Regression - Confusion Matrix\"\n",
    "        )\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(result1.Report)\n",
    "\n",
    "        ShowTitleBox(\"RESULTADOS KNN\",\n",
    "                     color=ConsoleColor.YELLOW,\n",
    "                     boxLineStyle=TitleBoxLineStyle.HEAVY)\n",
    "\n",
    "        print(f\"Best K: {result2.K}\")\n",
    "        print(f\"Accuracy: {result2.Accuracy:.4f}\")\n",
    "        print(f\"Precision: {result2.Precision:.4f}\")\n",
    "        print(f\"Recall: {result2.Recall:.4f}\")\n",
    "        print(f\"F1 Score: {result2.F1:.4f}\")\n",
    "\n",
    "        print(\"Confusion Matrix:\")\n",
    "        PlotConfusionMatrix(\n",
    "            result2.ConfusionMatrix,\n",
    "            classNames= result2.Model.classes_,\n",
    "            title=\"KNN - Confusion Matrix\"\n",
    "        )\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(result2.Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3e7f2",
   "metadata": {},
   "source": [
    "# BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET 1Ô∏è‚É£ Business Understanding - Entender el negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85564ba",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin (Diagnostic) ‚Äî Descripci√≥n de Columnas\n",
    "\n",
    "El dataset contiene medidas computadas a partir de im√°genes digitalizadas de tumores mamarios obtenidos mediante biopsia por aspiraci√≥n con aguja fina (FNA).  \n",
    "Incluye 569 observaciones y 32 columnas.\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Columnas de Identificaci√≥n y Diagn√≥stico\n",
    "\n",
    "### **1. id**\n",
    "Identificador √∫nico del registro. No se utiliza para entrenamiento.\n",
    "\n",
    "### **2. diagnosis**\n",
    "Diagn√≥stico final del tumor:\n",
    "- **M** = Maligno  \n",
    "- **B** = Benigno  \n",
    "\n",
    "Es la **variable objetivo** del dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Variables morfol√≥gicas del tumor\n",
    "\n",
    "Cada variable aparece en tres versiones:\n",
    "\n",
    "- **mean**: valor promedio  \n",
    "- **se**: error est√°ndar  \n",
    "- **worst**: peor valor (percentil 90 o m√°ximo observado)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚≠ê Radius\n",
    "Radio promedio del tumor, calculado como la distancia del centro al borde del n√∫cleo.\n",
    "- radius_mean  \n",
    "- radius_se  \n",
    "- radius_worst  \n",
    "\n",
    "## ‚≠ê Texture\n",
    "Desviaci√≥n est√°ndar de valores de intensidad de pixeles. Describe heterogeneidad.\n",
    "- texture_mean  \n",
    "- texture_se  \n",
    "- texture_worst  \n",
    "\n",
    "## ‚≠ê Perimeter\n",
    "Per√≠metro del n√∫cleo celular.\n",
    "- perimeter_mean  \n",
    "- perimeter_se  \n",
    "- perimeter_worst  \n",
    "\n",
    "## ‚≠ê Area\n",
    "√Årea del n√∫cleo celular, medida en p√≠xeles.\n",
    "- area_mean  \n",
    "- area_se  \n",
    "- area_worst  \n",
    "\n",
    "## ‚≠ê Smoothness\n",
    "Variaci√≥n local del radio. Describe qu√© tan suave o irregular es la forma.\n",
    "- smoothness_mean  \n",
    "- smoothness_se  \n",
    "- smoothness_worst  \n",
    "\n",
    "## ‚≠ê Compactness\n",
    "Calculado como:  \n",
    "`(perimeter¬≤ / area) ‚àí 1.0`  \n",
    "Indica cu√°n compacta es la forma.\n",
    "- compactness_mean  \n",
    "- compactness_se  \n",
    "- compactness_worst  \n",
    "\n",
    "## ‚≠ê Concavity\n",
    "Grado de concavidad del borde del n√∫cleo.\n",
    "- concavity_mean  \n",
    "- concavity_se  \n",
    "- concavity_worst  \n",
    "\n",
    "## ‚≠ê Concave Points\n",
    "N√∫mero de puntos con concavidad en el borde.\n",
    "- concave points_mean  \n",
    "- concave points_se  \n",
    "- concave points_worst  \n",
    "\n",
    "## ‚≠ê Symmetry\n",
    "Mide cu√°n sim√©trica es la forma de la c√©lula.\n",
    "- symmetry_mean  \n",
    "- symmetry_se  \n",
    "- symmetry_worst  \n",
    "\n",
    "## ‚≠ê Fractal Dimension\n",
    "Aproximaci√≥n a la dimensi√≥n fractal del borde celular.\n",
    "- fractal_dimension_mean  \n",
    "- fractal_dimension_se  \n",
    "- fractal_dimension_worst  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204d9e0",
   "metadata": {},
   "source": [
    "# BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET 2Ô∏è‚É£ Data preparation - Preparaci√≥n de los datos\n",
    "- Utilizando la funci√≥n `load_breast_cancer` de ScikitLearn podemos obtener el dataset de Breast Cancer Wisconsin.\n",
    "- Obtenemos el Dataset en \"X\" las columnas sin la columna objetivo y en \"y\" la columna a predecir; con el objetivo de entrenar modelos y realizar las predicciones.\n",
    "- Luego hacemos split del Dataset con un 80% para Train y 20% para Test.\n",
    "- Como son datos en diferentes escalas procedemos a escalar los valores utilizando un StandardScaler.\n",
    "- Finalmente mostramos las tablas de correlaci√≥n completa, fuerte y d√©bil con un umbral de 0.4. Teniendo un 43% de correlaciones fuertes y tiene sentido ya que mean, se y worst tienen relaci√≥n directa.\n",
    "- \n",
    "- Quedan listos los datos listos para utilizar en un entrenamiento con un algoritmo supervisado y posteriormente hacer los tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carga y preprocesa el dataset de Breast Cancer Wisconsin (Diagnostic).\n",
    "def LoadBreastCancerDataset(toInclude: list[str] | None = None) -> Dataset:\n",
    "    bc = cast(Bunch, load_breast_cancer(as_frame=True))\n",
    "    df: DataFrame = bc.frame.copy()\n",
    "\n",
    "    TARGET_NAME = \"target\"\n",
    "\n",
    "    # Separar X e y\n",
    "    X = df.drop(columns=[TARGET_NAME]).copy()\n",
    "\n",
    "    # Normalizar nombres de columnas\n",
    "    NormalizeColumnNames(X)\n",
    "\n",
    "    # Filtrar √∫nicamente columnas especificadas en toInclude\n",
    "    if toInclude is not None and len(toInclude) > 0:\n",
    "        # Tomar solo columnas existentes\n",
    "        colsToKeep = [c for c in toInclude if c in X.columns]\n",
    "        X = X[colsToKeep]\n",
    "\n",
    "    # Target invertido\n",
    "    y = 1 - df[[TARGET_NAME]].copy()\n",
    "    y.columns = [\"Diagnosis\"]\n",
    "\n",
    "    return Dataset(X, y)\n",
    "\n",
    "\n",
    "ShowTitleBox(\"BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET\", color=ConsoleColor.MAGENTA, boxLineStyle= TitleBoxLineStyle.BLOCK)\n",
    "ShowTitleBox(\"CARGANDO EL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerDataset = LoadBreastCancerDataset()\n",
    "\n",
    "ShowTitleBox(\"HACIENDO SPLIT AL DATASET\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerSplit: DatasetSplit = SplitDataset(breastCancerDataset, trainRatio=0.8)\n",
    "title = \"Split del Dataset\"\n",
    "ShowDatasetSplitInfo(breastCancerSplit, title)\n",
    "\n",
    "ShowTitleBox(\"HACIENDO ESCALADO AL SPLIT\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "breastCancerScaledSplit = ScaleDatasetSplit(breastCancerSplit)\n",
    "title = \"Split escalado\"\n",
    "ShowDatasetSplitHead(breastCancerScaledSplit, title)\n",
    "\n",
    "ShowTitleBox(\"MATRIZ DE CORRELACI√ìN\", color=ConsoleColor.CYAN, boxLineStyle= TitleBoxLineStyle.SIMPLE)\n",
    "CORR_UMBRAL = 0.4\n",
    "title = \"Breast Cancer Wisconsin (Diagnostic) Dataset - Original sin split\"\n",
    "_ = ShowDfCorrelation(breastCancerDataset.X, title, level=CorrelationType.ALL, showTable=True, figsize=(20,20), annotate=True, umbral=CORR_UMBRAL)\n",
    "_ = ShowDfCorrelation(breastCancerDataset.X, title, level=CorrelationType.STRONG, showTable=False, figsize=(20,20), annotate=True, umbral=CORR_UMBRAL)\n",
    "_ = ShowDfCorrelation(breastCancerDataset.X, title, level=CorrelationType.WEAK, showTable=False, figsize=(20,20), annotate=True, umbral=CORR_UMBRAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b7c64",
   "metadata": {},
   "source": [
    "# BREAST CANCER WISCONSIN (DIAGNOSTIC) DATASET 3Ô∏è‚É£ y 4Ô∏è‚É£ Modeling - Evaluating - Aplicaci√≥n del modelo y evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1fef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [\n",
    "    \"MeanRadius\",\n",
    "    \"MeanTexture\",\n",
    "    \"MeanPerimeter\",\n",
    "    \"MeanArea\",\n",
    "    \"MeanSmoothness\",\n",
    "    \"MeanCompactness\",\n",
    "    \"MeanConcavity\",\n",
    "    \"MeanConcavePoints\",\n",
    "    \"MeanSymmetry\",\n",
    "    \"MeanFractalDimension\"\n",
    "]\n",
    "\n",
    "cols2 = [\n",
    "    \"RadiusError\",\n",
    "    \"TextureError\",\n",
    "    \"PerimeterError\",\n",
    "    \"AreaError\",\n",
    "    \"SmoothnessError\",\n",
    "    \"CompactnessError\",\n",
    "    \"ConcavityError\",\n",
    "    \"ConcavePointsError\",\n",
    "    \"SymmetryError\",\n",
    "    \"FractalDimensionError\"\n",
    "]\n",
    "\n",
    "cols3 = [\n",
    "    \"WorstRadius\",\n",
    "    \"WorstTexture\",\n",
    "    \"WorstPerimeter\",\n",
    "    \"WorstArea\",\n",
    "    \"WorstSmoothness\",\n",
    "    \"WorstCompactness\",\n",
    "    \"WorstConcavity\",\n",
    "    \"WorstConcavePoints\",\n",
    "    \"WorstSymmetry\",\n",
    "    \"WorstFractalDimension\"\n",
    "]\n",
    "\n",
    "split1 = SplitDataset( LoadBreastCancerDataset())\n",
    "split2 = ScaleDatasetSplit( SplitDataset( LoadBreastCancerDataset()))\n",
    "split3 = ScaleDatasetSplit( SplitDataset( LoadBreastCancerDataset()), CreateScaler(ScalerType.MIN_MAX))\n",
    "split4 = ApplyPCA( ScaleDatasetSplit( SplitDataset( LoadBreastCancerDataset())))\n",
    "split5 = ApplyPCA( ScaleDatasetSplit( SplitDataset( LoadBreastCancerDataset()), CreateScaler(ScalerType.MIN_MAX)))\n",
    "split6 = SplitDataset( LoadBreastCancerDataset(toInclude=cols1))\n",
    "split7 = SplitDataset( LoadBreastCancerDataset(toInclude=cols2))\n",
    "split8 = SplitDataset( LoadBreastCancerDataset(toInclude=cols3))\n",
    "\n",
    "allSplits = [split1, split2, split3, split4, split5, split6, split7, split8]\n",
    "\n",
    "EvaluateSplits(allSplits, targetColumn=\"Diagnosis\")\n",
    "GenerateMetricsTable(allSplits, targetColumn=\"Diagnosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff452fe",
   "metadata": {},
   "source": [
    "# üèÅ Resultados üèÅ\n",
    "\n",
    "Se tiene 8 configuraciones distintas del dataset para probar:\n",
    "\n",
    "Dataset original (sin escalar)\n",
    "\n",
    "Dataset escalado (StandardScaler)\n",
    "\n",
    "Dataset escalado (MinMaxScaler)\n",
    "\n",
    "PCA aplicado sobre StandardScaler\n",
    "\n",
    "PCA aplicado sobre MinMaxScaler\n",
    "\n",
    "Solo primeras 10 columnas (Mean)\n",
    "\n",
    "Solo columnas de error (Error)\n",
    "\n",
    "Solo columnas ‚ÄúWorst‚Äù\n",
    "\n",
    "Y para cada uno, se calcula:\n",
    "\n",
    "- Regresi√≥n Log√≠stica\n",
    "- KNN\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Index</th>\n",
    "      <th>Type</th>\n",
    "      <th>Scaler</th>\n",
    "      <th>LR_Accuracy</th>\n",
    "      <th>LR_Precision</th>\n",
    "      <th>LR_Recall</th>\n",
    "      <th>LR_F1</th>\n",
    "      <th>KNN_BestK</th>\n",
    "      <th>KNN_Accuracy</th>\n",
    "      <th>KNN_Precision</th>\n",
    "      <th>KNN_Recall</th>\n",
    "      <th>KNN_F1</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1</td>\n",
    "      <td>RAW</td>\n",
    "      <td>None</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>11</td>\n",
    "      <td>0.95</td>\n",
    "      <td>0.95</td>\n",
    "      <td>0.95</td>\n",
    "      <td>0.95</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2</td>\n",
    "      <td>SCALED</td>\n",
    "      <td>Standard</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "      <td>5</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>3</td>\n",
    "      <td>SCALED</td>\n",
    "      <td>minmax</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>10</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>4</td>\n",
    "      <td>PCA</td>\n",
    "      <td>None</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>5</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "      <td>0.96</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>5</td>\n",
    "      <td>PCA</td>\n",
    "      <td>None</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>5</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "      <td>0.97</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>6</td>\n",
    "      <td>RAW</td>\n",
    "      <td>None</td>\n",
    "      <td>0.89</td>\n",
    "      <td>0.89</td>\n",
    "      <td>0.89</td>\n",
    "      <td>0.89</td>\n",
    "      <td>10</td>\n",
    "      <td>0.88</td>\n",
    "      <td>0.88</td>\n",
    "      <td>0.88</td>\n",
    "      <td>0.87</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>7</td>\n",
    "      <td>RAW</td>\n",
    "      <td>None</td>\n",
    "      <td>0.87</td>\n",
    "      <td>0.88</td>\n",
    "      <td>0.87</td>\n",
    "      <td>0.86</td>\n",
    "      <td>5</td>\n",
    "      <td>0.89</td>\n",
    "      <td>0.90</td>\n",
    "      <td>0.89</td>\n",
    "      <td>0.89</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>8</td>\n",
    "      <td>RAW</td>\n",
    "      <td>None</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>5</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "      <td>0.94</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "Escalando y aplicando PCA obtenemos buena precisi√≥n(Accuracy) tanto en LogisticRegression como en KNN (0.94 - 0.97).\n",
    "\n",
    "Todas las combinaciones con escalado con el score F1 se comportan bien teniendo valores entre 0.94 y 0.97.\n",
    "\n",
    "Utilizar ciertas columnas con son los splits 6,7 y 8 sin escalar dan el peor rendimiento. Al quitar columnas se quita parte del significado de los datos y puede hacer que el modelo falle.\n",
    "\n",
    "Utilizando MinMaxScaler en todos los scores tiene buenas puntuaciones. Dando como ganador el utilizar MinMaxScaler para este dataset en espec√≠fico.\n",
    "\n",
    "Al usar PCA aunque los datos pierdan sentido, pero se mantiene la calidad de los datos a pesar de reducir la dimensionalidad. Se logra detectar tumores malignos. Aplicar PCA nos ayuda a evitar la multicolinealidad en los datos. Por lo que es buena opci√≥n y recomendado en este dataset. \n",
    "\n",
    "PCA con MinMaxScaler es el ganador definitivo para este dataset.\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
